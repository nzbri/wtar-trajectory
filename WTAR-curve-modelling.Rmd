---
title: The Wechsler Test of Adult Reading is a stable measure of premorbid cognitive
  function in Parkinson's
author:
- name: Kyla-Louise Horne, PhD
  affiliation: '1'
- name: Reza Shoorangiz, PhD
  affiliation: '1,2,3'
- name: Daniel J. Myall, PhD
  affiliation: '1'
- name: Tim J. Anderson, MD, FRACP
  affiliation: '1,2,4'
- name: John C. Dalrymple-Alford, PhD
  affiliation: '1,2,5'
- name: Michael R. MacAskill, PhD
  affiliation: '1,2'
  corresponding: yes
  address: 66 Stewart St, Christchurch 8011, New Zealand
  email: michael.macaskill@nzbri.org
shorttitle: Parkinson's premorbid function
output:
  papaja::apa6_word:
  papaja::apa6_pdf:
    latex_engine: xelatex
link-citations: yes
csl: format/sage-vancouver.csl
bibliography: format/wtar-references.bib
appendix: 2021-wtar-supplementary.Rmd
linenumbers: yes
mask: no
draft: no
documentclass: apa6
classoption: man
affiliation:
- id: '1'
  institution: New Zealand Brain Research Institute, 66 Stewart St, Christchurch,
    New Zealand
- id: '2'
  institution: Department of Medicine, University of Otago, Christchurch; Christchurch,
    New Zealand
- id: '3'
  institution: Department of Electrical and Computer Engineering, University of Canterbury,
    Christchurch, New Zealand
- id: '4'
  institution: Department of Neurology, Christchurch Hospital, Christchurch, New Zealand
- id: '5'
  institution: School of Psychology, Speech, and Hearing, University of Canterbury,
    Christchurch, New Zealand
abstract: Background. Measures of premorbid cognitive function such as the 
  Wechsler Test of Adult Reading (WTAR) have been recommended as a means of 
  assessing current cognitive status in people with Parkinson's disease. 
  WTAR scores decline in Alzheimer's disease, however, and it has not been 
  formally demonstrated that they remain stable in spite of the substantial 
  cognitive deterioration that can occur in Parkinson's. 
  Objective. To assess long-term trajectories of WTAR scores in people with 
  Parkinson's as a function of age. Methods. From 253 Parkinson's and 57 
  Control participants who had completed at least two WTARs, we analysed scores
  using latent class trajectory modelling. Results. WTAR was quite stable within
  participants, even for those who progressed to dementia. 
  Conclusion. The WTAR is a stable measure in Parkinson's despite the presence 
  of substantial cognitive decline. Nonetheless, we contend that its other 
  properties make it poorly-suited for diagnosing cognitive impairment.
keywords: Parkinson disease, cognitive impairment, dementia, neuropsychology
wordcount: 'Abstract: up to 150 (145), main body: up to 1700 (2189: 334+539+420+896)'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = FALSE,
	message = FALSE,
	warning = FALSE
)
options(knitr.kable.NA = '')
```

```{r define-variables}
################################################################################
### 1. To save time taken by re-importing live data online everytime this  
###    document is generated, set the following variable to be FALSE. This will 
###    instead import static values from a locally-cached file.
### 2. Eventually, an anonymised cached version of the dataset(s) will be 
###    distributed publicly with these files, so that external (non-NZBRI) users
###    can also generate and alter the document, without needing the live data 
###    import functions provided by the in-house `chchpd` package.
### 3. We also can choose not to re-compute the latent class models on each run,
###    and instead use cached model objects to save re-computing them each time.
################################################################################
IMPORT_LIVE_DATA = FALSE

RUN_NEW_CUBIC_MODELS  = FALSE
RUN_NEW_LINEAR_MODELS = FALSE

################################################################################

# define the maximum number of classes to run models to:
max_classes_cubic = 5
max_classes_linear = 5

# define colour scheme values for normal, MCI, and dementia:
cog_colours <- c('#339900', '#FF9326', '#D92121')

# colour schemes for two categories (e.g. male/female):
orange_blue = c('#D55E00', '#0072B2')
blue_orange = c('#599BC2', '#E08F6B')
blue_orange_sat = c('#0072B2', '#D55E00')

fig_1_width = 17.5;   fig_1_height = 16.5

```

```{r import-packages}
# An NZBRI-only in-house package for importing the latest live data:
if (IMPORT_LIVE_DATA) {
  library(chchpd) # initial install via devtools::install_github('nzbri/chchpd')
}

# tidyverse libraries:
library(readr)       # to read/write locally cached .csv data files
library(dplyr)       # for data manipulation
library(tidyr)       # for fill & pivot_
library(lubridate)   # for date intervals
library(magrittr)    # for the %<>% operator
library(ggplot2)     # for visualisation
library(scales)      # improved labelling in ggplot
library(ggnewscale)  # allow multiple colour scales in ggplot
library(directlabels)# to label lines on plots
library(cowplot)     # combine multiple separate plots in one figure
library(lcmm)        # latent class models
library(parallel)    # for parallel computation
library(huxtable)    # tables that work in Word output
library(knitr)       # for kable pretty tables
library(kableExtra)  # extra kable options
library(papaja)      # for apa_table

```

```{r import-data}
# evaluated only if the chchpd package has been imported, to 
# access live data sources.
 
if (IMPORT_LIVE_DATA) { # put this here for when not knitting

participants = chchpd::import_participants(anon_id = FALSE) %>% 
    rename(group = participant_group)

sessions = chchpd::import_sessions() %>% 
  # the PDD follow-up sessions were mostly not coded as part of the 
  # Progression study, so gather sessions from both:
  filter(study %in% c('Follow-up', 'PDD Followup')) %>% 
  # but some sessions *were* entered in both studies, so remove any duplicates:
  group_by(session_id) %>% 
  filter(row_number() == 1) %>% 
  # this person's session seems to have a fictitious WTAR score (none should
  # have been gathered on that session, no original can be found, 
  # and the value changes so markedly from the two previous ones that it 
  # results in a separate class just to fit this one person). Can 
  # drop this filter step once the value is removed from the database:
  filter(session_id != '310PDS_2020-03-04')

np = chchpd::import_neuropsyc()
updrs = chchpd::import_motor_scores()

}
```

```{r collate-dataset}
if (IMPORT_LIVE_DATA) {

dat = right_join(participants, sessions, by = 'subject_id') %>%
  left_join(np, by = 'session_id') %>% 
  left_join(updrs, by = 'session_id')

dat = dat %>%
  filter(np_group %in% c('Control', 'PD'), # exclude atypical cases
         !is.na(cognitive_status),         # remove not-yet classified sessions
         !is.na(WTAR)) %>%                
  mutate(group = factor(group, levels = c('Control', 'PD'))) %>% 
  mutate(cognitive_status = factor(cognitive_status, 
                                   levels = c('N', 'MCI', 'D'),
                                   labels = c('Normal', 'MCI', 'Dementia'))) %>% 
  group_by(subject_id) %>% 
  arrange(years_from_baseline) %>%
  mutate(assessment_num = row_number()) %>% 
  mutate(n_sessions = max(assessment_num)) %>% 
  filter(n_sessions > 1) %>% # exclude cases without follow-up
  mutate(ever_demented = 'Dementia' %in% cognitive_status) %>% 
  # to make line colours match the destination point rather than the origin 
	# point, need to use a diagnosis variable that leads the current diagnosis
	# for each person by one step:
	mutate(cognitive_status_lead = lead(cognitive_status)) %>% 
	# this makes the last value for each person NA, which can cause issues. 
	# fill() replaces them with the latest previous diagnosis:
  fill(cognitive_status_lead) %>% 
  mutate(sampling_interval = 
           years_from_baseline - lag(years_from_baseline)) %>% 
  # should be much the same but here to be explicit:
  mutate(wtar_interval = 
           interval(start = lag(session_date), end = session_date)/years(1)) %>% 
  ungroup()


# lcmm insists on access to a numeric subject variable:
dat = dat %>% 
  mutate(subject_id = factor(subject_id)) %>% 
  mutate(subject_id_num = as.integer(subject_id))

# for lcmm we standardise the age to avoid problems with polynomial effects, 
# as per Proust-Lima et al. (2017). Note that we are using the grand mean age at 
# assessment, rather than averaging across some landmark age for each subject. 
# We use the same standardisation for the linear models, so we can compare them.
dat$age_std = (dat$age - mean(dat$age))/10

dat = dat %>% 
  arrange(subject_id_num, age) %>% 
  select(subject_id_num, group,	sex, symptom_onset_age,	diagnosis_age,
         education, age, age_std, wtar_interval, group, cognitive_status, 
         cognitive_status_lead, ever_demented, WTAR, MoCA, global_z, 
         attention_domain, executive_domain, visuo_domain,
         learning_memory_domain,	language_domain, H_Y,	Part_III)
         

# store a cached version of the dataset for optional access on subsequent runs 
# of generating this document:
dat %>% write_csv(file = 'data/dat_wtar.csv')

}

# Regardless of whether IMPORT_LIVE_DATA has been set to TRUE, we import from 
# a cached, static dataset rather to ensure consistency:
dat = read_csv(file = 'data/dat_wtar.csv') %>% 
  mutate(cognitive_status = factor(cognitive_status, 
                                   levels = c('Normal', 'MCI', 'Dementia')),
         cognitive_status_lead = factor(cognitive_status_lead, 
                                        levels = c('Normal', 'MCI', 'Dementia'))) %>% 
  # divide subjects into three panels in the figure:
  mutate(panel_label = 
           case_when(group == 'Control'     ~ 'Control',
                     ever_demented == FALSE ~ 'PD non-dementia',
                     TRUE                   ~ 'PD dementia'),
         panel_label = 
           factor(panel_label, 
                  levels = c('Control', 'PD non-dementia', 'PD dementia'))) %>% 
  # do this to avoid an issue with lcmm not correctly detecting numeric
  # column types in a tibble:
  as.data.frame()

```

# Introduction

In 2012, the International Parkinson and Movement Disorder Society published its
Task Force guidelines for the diagnosis of mild cognitive impairment in 
Parkinson's disease (PD-MCI).[@litvan2012_DiagnosticCriteriaMild] When the 
diagnosis is based on specific (rather than global) neuropsychological tests, 
significant impairment may be determined in three ways: (i) performance below 
appropriate norms, (ii) decline on serial testing, or (iii) decline from 
estimated premorbid levels. The first method tends to predominate in current 
research practice.[@aarsland2021_ParkinsonDiseaseassociatedCognitive] The latter 
two approaches, however, could be advantageous in resolving the ambiguity that 
poor current cognitive function might reflect long-standing low cognitive 
ability, rather than a recent disease-related deterioration. In practice, 
however, one seldom has reference to prior formal serial testing, and so a valid
method of estimating premorbid function is appealing. The Wechsler Test of Adult
Reading (WTAR)[@strauss2006_CompendiumNeuropsychologicalTests] was proposed in 
the guidelines as one of two recommended tests to estimate premorbid functioning
(along with the National Adult Reading Test, 
NART).[@strauss2006_CompendiumNeuropsychologicalTests] Both tests are based on 
being able to correctly pronounce phonetically-irregular English words, such as 
'porpoise' or 'hyperbole'. This ability has been shown to be preserved in the 
face of both normal ageing and a number of brain 
insults[@strauss2006_CompendiumNeuropsychologicalTests].

When the test was initially normed, it was tested in Parkinson's as well as a 
number of other neurological disorders, such as Huntington's, schizophrenia, and
traumatic brain injury. Only in Alzheimer's disease were the scores 
significantly lower than in matched 
controls.[@strauss2006_CompendiumNeuropsychologicalTests] Those results 
were published in 2001, however, well before the current MDS guidelines on 
diagnosing PD-MCI[@litvan2012_DiagnosticCriteriaMild] and Parkinson's 
dementia[@dubois2007_DiagnosticProceduresParkinson] were promulgated. It is 
therefore unclear to what extent those original findings are valid in the face 
of the significant cognitive deterioration that can occur in Parkinson's.

We therefore firstly sought to examine WTAR scores in a cognitively 
well-characterised sample, spanning the range from normal function through mild 
cognitive impairment to dementia. Secondly, we restricted the sample to 
participants who had completed a minimum of two WTARs, so that the stability of 
the measure within individuals over time could be examined.    

# Methods

```{r descriptives}
group_n = dat %>% 
  group_by(subject_id_num) %>% 
  mutate(session_num = row_number(),
         n_sessions = max(session_num)) %>% 
  slice_head() %>% # one row per subject
  group_by(group) %>% 
  summarise(n = n(), 
            min_sessions = min(n_sessions),
            mean_sessions = mean(n_sessions),
            sd_sessions = sd(n_sessions),
            max_sessions = max(n_sessions))

wtar_n = dat %>% 
  group_by(subject_id_num) %>% 
  mutate(session_num = row_number(),
         n_sessions = max(session_num)) %>% 
  slice_head() %>% # one row per subject
  ungroup() %>% 
  summarise(n = n(), 
            min_sessions = min(n_sessions),
            mean_sessions = mean(n_sessions),
            sd_sessions = sd(n_sessions),
            max_sessions = max(n_sessions),
            total_sessions = sum(n_sessions))

```

The New Zealand Parkinson's Progression Programme (NZP<sup>3</sup>) is a 
longitudinal study of a convenience prevalence sample of idiopathic Parkinson's, 
largely recruited from the specialist Movement Disorders Clinic at the New 
Zealand Brain Research Institute. The study commenced in 2007, with recruitment 
ongoing, and hence covers patients ranging from the recently-diagnosed to those 
with advanced disease. Inclusion and exclusion criteria have been described 
previously [@wood2016_DifferentPDMCICriteria]. For this analysis, we selected 
data only from the `r group_n$n[group_n$group == 'PD']` Parkinson's and 
`r group_n$n[group_n$group == 'Control']` Control participants who had completed
at least two WTARs (range 2 - `r wtar_n$max_sessions`, mean = 
`r wtar_n$mean_sessions`, total number of measures = `r wtar_n$total_sessions`).
The period between successive WTAR assessments was multi-modal, mostly 
clustering around intervals of one and two years, due to varying follow-up 
periods over the course of the study. Both patients and controls were classified
as having normal cognition, mild cognitive impairment, or dementia on the basis 
of a comprehensive neuropsychological 
battery[@dalrymple-alford2011_CharacterizingMildCognitive; @wood2016_DifferentPDMCICriteria], 
administered in accordance with MDS guidelines[@dubois2007_DiagnosticProceduresParkinson; @litvan2012_DiagnosticCriteriaMild]. Although the WTAR was assessed during each 
session, we did not actually use it in the cognitive diagnostic classification 
process: this was done on the basis of test scores falling ≥1.5 standard 
deviations below norms for PD-MCI and ≥1.5 standard deviations for PD dementia,[@dalrymple-alford2011_CharacterizingMildCognitive; @wood2016_DifferentPDMCICriteria]
rather than being compared to an estimated pre-morbid level. Characteristics of 
the sample are shown in Table \@ref(tab:table-1). All participants were speakers
of New Zealand English, and were assessed against the 
US norms of the WTAR, corrected for age, sex, and years of education (the 
provided ethnicity classifications were not useful in a New Zealand context and 
all participants were assessed against norms for "Whites"). 

## Latent class trajectory modelling

We fitted latent class trajectory models using the $hlme$ function from the 
$lcmm$ package [@proust-lima_estimation_2017] (version `r packageVersion('lcmm')`), 
running in the R statistical environment [@R-Core-Team_R_2021] 
(version `r R.version$major`.`r R.version$minor`). The dependent variable was 
WTAR-estimated premorbid IQ, initially modelled within each subject as a polynomial 
(cubic) function of age, to allow for non-linear trajectories. The resulting
trajectories were close to straight lines and thus we simplified the models to 
be a linear function of age. The models were unaware of any other variables 
(such as categorical MCI or dementia diagnoses). We fitted five separate models,
with the specified number of latent classes increasing from 1 to 5. The model 
with just one latent class was used to provide starting values for the 
subsequent models with multiple classes. The `gridsearch()` function of the 
`lcmm` package was used to run 5000 departures from random initial values for 
each multi-class model, using the one-class model to generate those starting 
values from. The maximum number of iterations within the `hlme()` function was 
set at 1000. ***Check with Daniel & Reza on the phrasing of this process.*** 
Parameters corresponding to the best log-likelihood were used as initial values 
for the final estimation of the parameters [@proust-lima_estimation_2017]. 
Selection of the optimal model was on the basis of selecting the one with the 
lowest BIC value.

```{r table-1}
table_df = dat %>% 
  group_by(subject_id_num) %>% 
  arrange(age) %>% 
  slice_tail() %>% # last observation per subject
  group_by(group) %>% 
  summarise(n = n(),
            Male   = scales::percent_format(accuracy = 0.1)(sum(sex == 'Male')/n),
            Age = paste0(sprintf('%.1f', mean(age)), ' (', sprintf('%.1f',sd(age)), ')'),
            Education = paste0(sprintf('%.1f', mean(education)), ' (', sprintf('%.1f', sd(education)), ')'),
            WTAR = paste0(sprintf('%.1f', mean(WTAR)), ' (', sprintf('%.1f', sd(WTAR)), ')'),
            Normal = scales::percent_format(accuracy = 0.1)(sum(cognitive_status == 'Normal')/n),
            MCI    = scales::percent_format(accuracy = 0.1)(sum(cognitive_status == 'MCI')/n),
            Dementia = scales::percent_format(accuracy = 0.1)(sum(cognitive_status == 'Dementia')/n)) %>% 
  mutate(n = as.character(n)) %>% 
  pivot_longer(n:Dementia) %>% 
  pivot_wider(names_from = 'group')

table_df %>% 
  mutate(name = case_when(name == 'Education' ~ 'Education (years)',
                          name == 'Normal'    ~ 'Normal cognition',
                          TRUE                ~ name)) %>% 
  rename(' '           = name,
         "Parkinson's" = PD) %>%
  apa_table(caption = "Demographics of the Parkinson's and Control groups, as at their latest assessment.", align = 'lrr') #%>% 
  # kable(caption = "Demographics of the Parkinson's and Control groups, as at their latest assessment.", align = 'lrr') %>% #, vline = '')#, booktabs = TRUE) %>%
  #kable_styling(position = 'center') %>%
  #row_spec(0, bold = TRUE)

```


## Reproducibility

The code and anonymised dataset extracts sufficient to reproduce the analyses 
and generate this manuscript are publicly available at [github.com/nzbri/wtar-trajectory](https://github.com/nzbri/wtar-trajectory). 
There are a number of decisions that can affect the outcome of a latent class 
modelling analysis and therefore in the Supplementary Material we report against
the 16-item checklist "Guidelines for Reporting on Latent Trajectory Studies".[@van_de_schoot_grolts-checklist_2017]

# Results

```{r wtar-modelling-cubic, include=FALSE}

# prepare list to hold models with 1 through max_classes_cubic classes:
cubic_models = list()

if (RUN_NEW_CUBIC_MODELS) {

  # make use of parallel computation to speed up working through the large number of 
  # iterations to be used for each model:
  num_cores = parallel::detectCores()
  cl = parallel::makeCluster(num_cores)
  
  # currently have to coerce data to a dataframe (done above), as tibbles lead to 
  # a bug with the subject id column not being accepted by lcmm as numeric.
  
  # use the 1-class model to set initial start values:
  cubic_models[[1]] <- lcmm::hlme(WTAR ~ poly(age_std, degree = 3, raw = TRUE), 
                                  random = ~1 + poly(age_std, degree = 3, raw = TRUE),
                                  subject = 'subject_id_num', ng = 1, 
                                  data = dat)
  saveRDS(cubic_models[[1]], 'models/cubic_WTAR_1.RDS') # cache to disk
  
  # for each higher-class model, run with 5000 random starts based on the initial
  # one-class model, then run the selected one up to 1000 times to (hopeful) convergence:
  
  for (class_num in 2:max_classes_cubic) {
    
    print(class_num)
    
    # need to explicitly pass some variables to the namespace of each process, or the 
    # gridsearch and hlme functions below will trip up by not "knowing" some of their
    # parameters:
    parallel::clusterExport(cl, c('class_num', 'cubic_models'))
    
    cubic_models[[class_num]] <-
      lcmm::gridsearch(rep = 5000, maxiter = 100, minit = cubic_models[[1]], cl = cl,
                       hlme(WTAR ~ poly(age_std, degree = 3, raw = TRUE), 
                            random = ~1 + poly(age_std, degree = 3, raw = TRUE), 
                            ng = class_num, nwg = TRUE, maxiter = 1000,
                            mixture = ~ poly(age_std, degree = 3, raw = TRUE),
                            subject = 'subject_id_num', data = dat))
    
    saveRDS(cubic_models[[class_num]], paste0('models/cubic_WTAR_', class_num, '.RDS'))
  }
  
  parallel::stopCluster(cl)
  
} else { # use previously-computed cubic models:
  
  for (class_num in 1:max_classes_cubic) {
    cubic_models[[class_num]] = readRDS(paste0('models/cubic_WTAR_', class_num, '.RDS'))
  }
}

cubic_WTAR_model_table = 
  summarytable(cubic_models[[1]], cubic_models[[2]], cubic_models[[3]], cubic_models[[4]], cubic_models[[5]],
               which = c('G', 'loglik', 'npm', 'BIC', 'SABIC', 
                         'entropy', '%class')) %>% 
  as_tibble()

# select model, on the basis of one that converged and had the lowest BIC:
chosen_cubic_classes = 1
chosen_cubic_model   = cubic_models[[chosen_cubic_classes]]

# create a vector of ages to predict against, centred on the mean across all
# sessions, and in decades rather than years to limit polynomial instabilities):
mean_age = mean(dat$age) 
new_data_cubic = 
  data.frame(age = seq(from = 43, to = 89, by = 0.5)) %>% 
  mutate(age_std = (age - mean_age)/10)

# create a dataframe that contains predictions for all candidate models
# (will be used in the supplementary material).
predictions = list()

for (i in 1:max_classes_cubic) {
  prediction = lcmm::predictY(cubic_models[[i]], newdata = new_data_cubic, 
                              var.time = 'age_std', draws = TRUE)
  predictions[[i]] = 
    as.data.frame(prediction$pred) %>% # extract just the predicted values
    cbind(new_data_cubic) # and add in the corresponding age values
  predictions[[i]]$ng = i  # and label with the number of classes
}

# the first one needs to be modified so that it can act as the template to 
# row bind to the others:
predictions[[1]] = predictions[[1]] %>% # add a suffix to the variable names
  rename('Ypred_class1' = 'Ypred', 
         'lower.Ypred_class1' = 'lower.Ypred', 
         'upper.Ypred_class1' = 'upper.Ypred') %>% 
  select(ng, age, age_std, everything()) # set the order for the resulting dataframe

cubic_predictions = bind_rows(predictions[1:5]) %>% 
  # reshape to allow ggplotting:
  pivot_longer(cols = Ypred_class1:last_col(), 
               names_to = c('line', 'class'), names_sep = '_',
               values_to = 'predicted_WTAR') %>% 
  pivot_wider(names_from = line, values_from = predicted_WTAR) %>% 
  filter(!is.na(Ypred)) %>% 
  arrange(ng, class, age)

```

```{r wtar-modelling-linear, include=FALSE}

# prepare list to hold models with 1 through max_classes_linear classes:
linear_models = list()

if (RUN_NEW_LINEAR_MODELS) {
  
  # make use of parallel computation to speed up working through the large 
  # number of iterations to be used for each model:
  num_cores = parallel::detectCores()
  cl = parallel::makeCluster(num_cores)
  
  # currently have to coerce data to a dataframe (done above), as tibbles lead 
  # to a bug with the subject id column not being accepted by lcmm as numeric.
  
  # use the 1-class model to set initial start values:
  linear_models[[1]] <- lcmm::hlme(WTAR ~ age_std, 
                                 random = ~1 + age_std,
                                 subject = 'subject_id_num', ng = 1, 
                                 data = dat)
  saveRDS(linear_models[[1]], 'models/linear_WTAR_1.RDS') # cache to disk
  
  # for each higher-class model, run with 5000 random starts based on the initial
  # one-class model, then run the selected one up to 1000 times to (hopeful) convergence:
  
  for (class_num in 2:max_classes_linear) {
    
    print(class_num)
    
    # need to explicitly pass some variables to the namespace of each process, 
    # or the gridsearch and hlme functions below will trip up by not "knowing" 
    # some of their parameters:
    parallel::clusterExport(cl, c('class_num', 'linear_models'))
    
    linear_models[[class_num]] <- 
      lcmm::gridsearch(rep = 5000, maxiter = 100, minit = linear_models[[1]], cl = cl,
                       hlme(WTAR ~ age_std, 
                            random = ~1 + age_std, 
                            ng = class_num, nwg = TRUE, 
                            mixture = ~ age_std, maxiter = 1000,
                            subject = 'subject_id_num', data = dat))
    
    saveRDS(linear_models[[class_num]], paste0('models/linear_WTAR_', class_num, '.RDS'))
  }
  
  parallel::stopCluster(cl)
  
} else { # use previously-computed linear models:
  
  for (class_num in 1:max_classes_linear) {
    linear_models[[class_num]] = readRDS(paste0('models/linear_WTAR_', class_num, '.RDS'))
  }
  
}

linear_WTAR_model_table = 
  summarytable(linear_models[[1]], linear_models[[2]], linear_models[[3]], linear_models[[4]], linear_models[[5]],
               which = c('G', 'loglik', 'npm', 'BIC', 'SABIC', 
                         'entropy', '%class')) %>% 
  as_tibble()

# select model, on the basis of one that converged and had the lowest BIC:
chosen_linear_classes = 2
chosen_linear_model   = linear_models[[chosen_linear_classes]]
coeffs = coef(chosen_linear_model)

# create a vector of ages to predict against, centred on the mean across all
# sessions, and in decades rather than years to be consistent with the cubic 
# modelling where we need to limit instabilities):
mean_age = mean(dat$age) 
new_data_linear = 
  data.frame(age = seq(from = 43, to = 89, by = 0.5)) %>% 
  mutate(age_std = (age - mean_age)/10)

# create a dataframe that contains predictions for all candidate models
predictions = list()

for (i in 1:max_classes_linear) {
  prediction = lcmm::predictY(linear_models[[i]], newdata = new_data_linear, 
                              var.time = 'age_std', draws = TRUE)
  predictions[[i]] = 
    as.data.frame(prediction$pred) %>% # extract just the predicted values
    cbind(new_data_linear) # and add in the corresponding age values
  predictions[[i]]$ng = i  # and label with the number of classes
}

# the first one needs to be modified so that it can act as the template to 
# row bind to the others:
predictions[[1]] = predictions[[1]] %>% # add a suffix to the variable names
  rename('Ypred_class1' = 'Ypred', 
         'lower.Ypred_class1' = 'lower.Ypred', 
         'upper.Ypred_class1' = 'upper.Ypred') %>% 
  select(ng, age, age_std, everything()) # set the order for the resulting dataframe

linear_predictions = bind_rows(predictions[1:5]) %>% 
  # reshape to allow ggplotting:
  pivot_longer(cols = Ypred_class1:last_col(), 
               names_to = c('line', 'class'), names_sep = '_',
               values_to = 'predicted_WTAR') %>% 
  pivot_wider(names_from = line, values_from = predicted_WTAR) %>% 
  filter(!is.na(Ypred)) %>% 
  arrange(ng, class, age)
  
chosen_linear_predictions = linear_predictions %>% 
  filter(ng == chosen_linear_classes) %>% 
  mutate(class = 
           factor(class, 
                  levels = c('class2', 'class1'),
                  labels = c('High performers', 'Typical'))) %>% 
  rename(class_for_lines = class)

# link subjects to their assigned classes:
dat_with_classes = dat %>% 
  left_join(chosen_linear_model$pprob, by = 'subject_id_num') %>% 
   mutate(class = 
           factor(class, 
                  levels = c('2', '1'),
                  labels = c('High performers', 'Typical'))) %>% 
  rowwise() %>% 
  mutate(class_probability = max(c(prob1, prob2)))

# get a dataframe with just one row per subject
individuals = dat_with_classes %>% 
  group_by(subject_id_num) %>% arrange(age) %>% 
  slice_tail()

class_proportions = individuals %>% 
  group_by(class) %>% 
  tally() %>%
  mutate(proportion = scales::percent_format(accuracy = 1)(n/sum(n)))

class_proportions_by_group = individuals %>% 
  group_by(group, class) %>% 
  tally() %>% group_by(group) %>% 
  mutate(proportion = scales::percent_format(accuracy = 1)(n/sum(n)))
```

The raw data showed that WTAR scores were relatively constant over time (see 
Figure \@ref(fig:figure-1)A), despite the substantial declines that could occur 
in overall cognitive function (Figure \@ref(fig:figure-1)B). Initially, however,
we modelled WTAR scores as a polynomial (cubic) function of age, to allow for the
depiction of any sub-clusters exhibiting curvilinear changes. The optimal cubic 
model showed a relatively flat trajectory, and we therefore shifted to modelling
WTAR as a linear function of age, fitting candidate models ranging from one to 
five latent trajectory classes. We selected the two-class model on the basis of 
it having the lowest BIC value. Full details on the modelling process are 
provided in Supplementary Material.

We labelled the two resulting trajectory classes 'Typical' and 
'High performers'. Individuals were assigned to the class for which they had the
highest posterior classification probability. The mean assigned probability was 
`r round(mean(individuals$class_probability), digits = 2)` 
(`r round(sd(individuals$class_probability), digits = 2)`), with a value of 0.7 
being regarded as acceptable model performance.[@lennon_framework_2018] The 
Typical trajectory captured 
`r class_proportions$proportion[class_proportions$class == 'Typical']` of all 
participants (`r class_proportions_by_group$proportion[class_proportions_by_group$class == 'Typical' & class_proportions_by_group$group == 'PD']` of the PD and `r class_proportions_by_group$proportion[class_proportions_by_group$class == 'Typical' & class_proportions_by_group$group == 'Control']` of Control participants). The 
'High performers' trajectory (capturing the remaining 
`r class_proportions$proportion[class_proportions$class == 'High performers']` 
of all participants) had an intercept of 
`r sprintf('%.1f', coeffs[names(coeffs) == 'intercept class2'])`, representing 
the estimated WTAR score of a person at the mean age of assessment 
(`r sprintf('%.1f', mean_age)` years). The slope of this trajectory 
indicated a decline of 
`r sprintf('%.1f', coeffs[names(coeffs) == 'age_std class2'])` 
points per decade (effectively flat). 
***[TODO: Reza/Daniel - not sure how to get uncertainty around these estimates]*** 
The Typical trajectory, by contrast had an intercept of 
`r sprintf('%.1f', coeffs[names(coeffs) == 'intercept class1'][2])`, 
***[TODO: Reza/Daniel - not sure why two coefficients with this name are returned, with one having a value that does not seem related to the actual one ]*** gently declining at a rate of 
`r sprintf('%.1f', coeffs[names(coeffs) == 'age_std class1'])` points per decade.

***TODO:*** What other descriptive results might be useful (e.g. mean 
within-subject standard deviation, or range of WTAR scores? Not great for those 
with only two scores, though)? 

(ref:fig-1-caption) ***(A.)*** Longitudinal WTAR score trajectories for all 
individuals, divided into Controls, Parkinson's participants who remained 
dementia-free, and those who developed dementia. Also shown are the two 
predicted latent class trajectories (blue ribbon = _High performers_, brown 
ribbon = _Typical_). ***(B.)***  Global cognitive z-scores for the Parkinson's 
participants in the lower panel of (A) (those who developed dementia). Overall 
cognitive performance declined dramatically, in contrast to their relatively 
stable WTARs scores. This was regardless of their latent class (blue and brown 
lines). In each panel, current cognitive status is shown as cognitively normal 
(green circles), mild cognitive impairment (orange triangles), or dementia (red 
squares). Upon reaching dementia, the WTAR was not assessed again.

```{r figure-1, fig.align='center', fig.cap='(ref:fig-1-caption)', fig.height=fig_1_height/2.54, fig.width=fig_1_width/2.54, warning=FALSE}

# upper panel, of WTAR scores by age:
figure_1_upper = dat_with_classes %>% 
  ggplot(aes(x = age)) +
  facet_grid(panel_label ~ .) +
  scale_colour_manual(values = c('blue', 'brown'), name = 'Class', guide = 'none') + 
  scale_fill_manual(values = c('blue', 'brown'), name = 'Class', guide = 'none') + 
  geom_ribbon(dat = chosen_linear_predictions,
              aes(ymin = lower.Ypred, ymax = upper.Ypred, fill = class_for_lines),
              colour = NA, alpha = 0.2) +
  geom_line(dat = chosen_linear_predictions,
            aes(y = Ypred, colour = class_for_lines), 
            size = 0.25, linetype = 'dashed') +
  geom_line(aes(y = WTAR, colour = class, group = subject_id_num), 
            alpha = 1.0, size = 0.1) +
  new_scale_color() + new_scale_fill() +
  scale_colour_manual(values = cog_colours, name = 'Cognitive status') + 
  scale_fill_manual(values = cog_colours, name = 'Cognitive status') +
  # setting stroke = 0.1 gives nice sharp shapes:
  scale_shape_manual(values = c(21, 25, 22), name = 'Cognitive status') +
  geom_point(aes(y = WTAR, fill = cognitive_status,
                 #colour = cognitive_status, # minimal border stroke
                 shape = cognitive_status), colour = 'white', size = 1.0, stroke = 0.1) +

  scale_x_continuous(limits = c(42, 89.9), expand = c(0,0),
                     labels = scales::label_number(suffix = ' years')) +
  scale_y_continuous(limits = c(80, 130)) +
  labs(title = 'A. Longitudinal WTAR scores by group',
       subtitle = 'Showing raw scores and the two predicted latent class trajectories',
       x = NULL, y = NULL) +
  theme_bw() +
  theme(plot.title = element_text(face = 'bold', size = 9),
        plot.subtitle = element_text(size = 8),
        axis.text = element_text(size = 7, colour = 'black'),
        axis.ticks.y = element_line(colour = '#E8E8E8', size = 0.25),
        axis.ticks.x = element_blank(),
        panel.grid.major.y = element_line(colour = '#E8E8E8', size = 0.25),
        panel.grid.major.x = element_line(colour = '#C0C0C0', size = 0.5, 
                                          linetype = 'dotted'),
        panel.grid.minor = element_blank(),
        strip.text = element_text(face = 'plain', colour = 'black', size = 8),
        strip.background = element_rect(colour = '#C0C0C0', fill = '#C0C0C0'),
        panel.border = element_rect(colour = '#C0C0C0', size = 0.5),
        legend.pos = 'none', #c(0.09, 0.095),
        legend.margin = margin(c(1, 1, 1, 1), unit = 'mm'),
        legend.spacing.y = unit(1, 'mm'), # spacing between title & items
        legend.key.size = unit(2.5, 'mm'), # spacing between items
        legend.title = element_text(face = 'bold', size = 6),
        legend.text = element_text(size = 7))

# lower panel, of z-score trajectories of dementia-converters only:
figure_1_lower = dat_with_classes %>% 
  filter(panel_label == 'PD dementia') %>% 
  ggplot(aes(x = age, y = global_z)) +
  facet_grid(panel_label ~ .) +
  geom_line(aes(group = subject_id_num, colour = class), 
            alpha = 0.6, size = 0.25, show.legend = FALSE) +
  # setting stroke = 0.1 gives nice sharp shapes:
  geom_point(aes(fill = cognitive_status,
                 #colour = cognitive_status, # minimal border stroke
                 shape = cognitive_status), colour = 'white', size = 1.0, stroke = 0.1) +
  scale_colour_manual(values = c('blue', 'brown'), name = 'Class', guide = 'none') +
  scale_fill_manual(values = cog_colours, name = 'Cognitive status') +
  scale_shape_manual(values = c(21, 25, 22), name = 'Cognitive status') +
  scale_x_continuous(limits = c(42, 89.9), expand = c(0,0),
                     labels = scales::label_number(suffix = ' years')) +
  labs(title = 'B. Global cognitive z-scores',
       subtitle = 'Of those PD participants who developed dementia',
       x = NULL, y = NULL) + 
  theme_bw() +
  theme(plot.title = element_text(face = 'bold', size = 9),
        plot.subtitle = element_text(size = 8),
        axis.ticks = element_line(colour = '#E8E8E8', size = 0.25),
        axis.text = element_text(size = 7, colour = 'black'),
        panel.grid.major.y = element_line(colour = '#E8E8E8', size = 0.25),
        panel.grid.major.x = element_line(colour = '#C0C0C0', size = 0.5, 
                                          linetype = 'dotted'),
        panel.grid.minor = element_blank(),
        strip.text = element_text(face = 'plain', colour = 'black', size = 8),
        strip.background = element_rect(colour = '#C0C0C0', fill = '#C0C0C0'),
        panel.border = element_rect(colour = '#C0C0C0', size = 0.5),
        legend.position = c(0.085, 0.46), # 0.64 puts it in the top panel
        legend.margin = margin(c(1, 1, 1, 1), unit = 'mm'),
        legend.spacing.y = unit(1,'mm'), # spacing between title & items
        legend.key.size = unit(3.0,'mm'), # spacing between items
        legend.title = element_text(face = 'bold', size = 7),
        legend.text = element_text(size = 7))

figure_1 = cowplot::plot_grid(figure_1_upper, figure_1_lower, nrow = 2, axis = 'l',
                              align = 'v', rel_heights = c(1.0, 0.43))

figure_1

ggsave('images/wtar-figure-1.pdf', width = fig_1_width, height = fig_1_height,
       units = 'cm')
```

# Discussion

***TODO:*** [@statucka2021_MulticulturalismChallengeCognitive] - shows that 
MoCA has cross-cultural validity issues even within a country. 

The raw data showed that WTAR scores were relatively stable over time in both 
controls and people with Parkinson's, despite many of the latter developing 
dementia over the course of the study (see Table \@ref(tab:table-1)). 
Nonetheless, latent class trajectory analysis revealed that in our particular 
sample, people fell into one of two longitudinal clusters (Figure 
\@ref(fig:figure-1)). Those with very high initial WTAR scores maintained 
near-ceiling performance levels, even if they subsequently developed dementia. 
The remaining 
`r class_proportions$proportion[class_proportions$class == 'Typical']` of 
participants had a wider range of initial scores, but were again 
relatively stable, with a mean estimated decline of only 
`r sprintf('%.1f', coeffs[names(coeffs) == 'age_std class1'])` points per 
decade.

Measures of pre-morbid function are closely tied to the concept of cognitive 
reserve.[@stern2012_CognitiveReserveAgeing] For example, if people with
PD-MCI typically had a low measure of premorbid function, then this would 
support high cognitive reserve being protective against subsequent decline. This
can lead to circular reasoning if the premorbid measure is not reliable, however.
But if the disease process reduces performance on that measure, then the inference 
would no longer be valid. The findings shown here, of stable scores despite 
current cognitive impairment, support the use of WTAR as a valid indicator of 
cognitive reserve in Parkinson's.

There are reservations about the use of the WTAR, however. It is outdated,
inasmuch as it was originally devised to estimate IQ scores from the WAIS-III 
(released in 1997). That has been superseded by the WAIS-IV (2008), and in turn, 
the WAIS-V is currently under development. The TOPF (Test of Premorbid 
Function) was designed as a successor to the WTAR and estimates WAIS-IV 
IQ, but it has had limited uptake.[@bright2020_ComparisonMethodsEstimating] The 
Flynn effect[@flynn1999_SearchingJusticeDiscovery] is the robust finding that IQ
scores increase substantially over time (by up to 1 standard deviation per 
generation). Our sample would have been born approximately a generation after 
their age-matched WAIS III normative sample group and that might explain their
apparently elevated estimated IQ levels.

The WTAR (and NART) are also limited in that they are inherently tied to 
peculiarities of written and spoken English. Many other languages have no 
equivalent irregularities in their mappings of graphemes to phonemes, and hence 
analogous tests of premorbid function cannot be devised for them. Japanese can 
be written in a syllabary (Hiragana), in which each of several dozen graphemes 
corresponds to a single phoneme. Once a reader knows those correspondences, they
can reliably pronounce words they have never encountered before, purely on the 
basis of their written representation. Despite that, a Japanese analogue of the 
NART has nonetheless been attempted[@matsuoka2006_EstimationPremorbidIQ]. The 
'JART' relies upon irregularities in compound words written using Chinese-style 
ideographs (Kanji). There are thousands of these characters, each having lexical
meaning that must be learned individually. The same ideograph may be pronounced 
differently depending on its context. These irregularities are the basis for the 
JART but make it much more loaded on semantic than phonemic knowledge. That JART
scores are preserved in Alzheimer's[@matsuoka2006_EstimationPremorbidIQ] imply 
that it is not actually a perfect analogue of English-based tests of premorbid 
function. Even across varieties of English, both between and within countries, 
the US- and UK-based selection of words can be problematic. For example, the 
TOPF was found to not reliably predict WAIS IV IQ in New Zealand English 
speakers of Māori ethnicity.[@dudley2017_TestPremorbidFunctioning] After the 
commencement of our study, a New Zealand Adult Reading Test (NZART) was 
created[@starkey2011_DevelopmentNewZealand], with a more culturally relevant 
selection of words, but will require further development to supplant the 
established international tests. In subsequent revisions of the PD-MCI criteria, 
if premorbid measures continue to be advocated, we recommend that more 
attention should be given to alternative 
techniques[@franzen1997_MethodsEstimatingPremorbid] that could be valid in a 
wider international and cross-cultural context.

The PD-MCI guidelines do not actually formalise how the results of premorbid 
function tests should be used in practice to demonstrate decline in cognitive 
functioning[@marras2014_ToolsTradeState]. We are aware of only one 
study[@marras2013_MeasuringMildCognitive] that has compared the norms-based vs 
premorbid estimation approaches to establishing cognitive impairment. They 
converted the WTAR-estimated full-scale IQ to a z-score and used that as the 
reference against which to test each individual neuropsychological test z-score, 
with a test that was lower by more than 1.5 SD deemed impaired. Of a sample of 
139 non-demented people with Parkinson's, the WTAR method classified many more 
of them as having PD-MCI (79%) than a norms-based Level II 
classification method (33%). Marras _et al._ interpreted this as evidence that 
most people with Parkinson's have undergone at least some decline relative to 
their premorbid function. Conversely it might be that the WTAR simply 
over-estimated that level of function - just as in our sample, where the 
distribution of estimated IQ values were well above the supposed population mean
of 100.

In summary, WTAR is a measure that is exceptionally stable in Parkinson's, 
despite substantial deterioration in current cognitive functioning. This can 
make it a valid research tool to probe cognitive reserve and premorbid 
function across groups. It appears to overestimate the premorbid IQ however, 
making it unsuitable to establish a decline in function within individuals. 
All such measures may suffer from cross-cultural word choice issues even across 
different varieties of English. Analogous tests are not even meaningful to 
create in languages that do not exhibit English's substantial 
grapheme:phoneme irregularities. Hence we recommend that such tests of premorbid
function no longer be advocated in MDS guidelines as one of the means of 
formally establishing cognitive decline in Parkinson's.

# References


