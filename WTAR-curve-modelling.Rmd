---
title: "The Wechsler Test of Adult Reading in Parkinson’s: stable premorbid measure despite cognitive decline"
author:
- name: Kyla-Louise Horne, PhD
  affiliation: '1'
- name: Reza Shoorangiz, PhD
  affiliation: '1,2,3'
- name: Daniel J. Myall, PhD
  affiliation: '1'
- name: Tim J. Anderson, FRACP, MD
  affiliation: '1,2,4'
- name: John C. Dalrymple-Alford, PhD
  affiliation: '1,2,5'
- name: Michael R. MacAskill, PhD
  affiliation: '1,2'
  corresponding: yes
  address: 66 Stewart St, Christchurch 8011, New Zealand
  email: michael.macaskill@nzbri.org
shorttitle: Parkinson's premorbid function
output:
  papaja::apa6_pdf:
    latex_engine: xelatex
  papaja::apa6_word:
link-citations: yes
csl: format/bmj.csl
bibliography: format/wtar-references.bib
appendix: WTAR-supplementary.Rmd
linenumbers: yes
mask: no
draft: no
documentclass: apa6
classoption: man
affiliation:
- id: '1'
  institution: New Zealand Brain Research Institute, 66 Stewart St, Christchurch,
    New Zealand
- id: '2'
  institution: Department of Medicine, University of Otago, Christchurch; Christchurch,
    New Zealand
- id: '3'
  institution: Department of Electrical and Computer Engineering, University of Canterbury,
    Christchurch, New Zealand
- id: '4'
  institution: Department of Neurology, Christchurch Hospital, Christchurch, New Zealand
- id: '5'
  institution: School of Psychology, Speech, and Hearing, University of Canterbury,
    Christchurch, New Zealand
abstract: Background. The Wechsler Test of Adult Reading (WTAR) has been
  recommended as a  measure of premorbid cognitive function and as a reference
  against which to assess current cognitive status in people with Parkinson’s 
  disease. To fulfil either role, however, it needs to be shown that WTAR scores
  remain stable in the presence of the substantial cognitive deterioration that
  can occur in Parkinson’s. Objective. To assess long-term trajectories of WTAR
  scores in people with  Parkinson's as a function of age. Methods. From 252
  Parkinson's and 57 Control participants who had completed at least two WTARs,
  we analysed scores over time using latent class trajectory modelling. This
  allows for individual participants to be classified into data-driven clusters,
  depending on the shape of their longitudinal trajectory. Results. WTAR scores
  were reasonably stable within both Controls and Parkinson's participants, even
  for those who progressed to dementia. In both groups and regardless of current
  cognitive status, scores were higher than expected from population norms. 
  Conclusion. The WTAR is stable in Parkinson's even when participants decline
  from normal cognitive function to dementia. Nonetheless, its apparent 
  over-estimation of premorbid IQ and restriction to English speakers makes it
  poorly-suited for diagnosing cognitive impairment in individuals with 
  Parkinson's.
keywords: Parkinson disease, cognitive impairment, dementia, neuropsychology, 
  premorbid function
wordcount: 'Abstract: 197 (of 250), main body: 2371 (of 3700)'
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
## NB notice the chunk_output_type: console setting in the YAML header above.
## This was part of addressing an issue where one of the linear models would
## converge in R, "but kept failing during knitting in Rmarkdown. The problem 
## seemed to be caused by the parallel package and how it generates random 
## numbers" also we now "create/destroy a new parallel pool within the 
## for-loop"- problem and solution identified by Reza. 

knitr::opts_chunk$set(
	echo = FALSE,
	message = FALSE,
	warning = FALSE)
options(knitr.kable.NA = '')

```

```{r define-variables}
################################################################################
### 1. NZBRI users can save the time taken to re-import live data online 
###    every time this document is generated, by setting the IMPORT_LIVE_DATA 
###    variable to be FALSE. This will instead import static values from a 
###    locally-cached .csv data file.
### 2. That anonymised cached version of the dataset is distributed publicly 
###    with these files, so that external (non-NZBRI) users can also generate 
###    and alter the document, without needing the live data import functions 
###    provided by the in-house `chchpd` package.
### 3. You should usually choose not to re-compute the latent class models on 
###    each run, as this is very time-consuming (hours to days). Instead use 
###    the cached model objects to save re-computing them each time, by setting 
###    RUN_NEW_CUBIC_MODELS and RUN_NEW_LINEAR_MODELS to FALSE.
################################################################################
IMPORT_LIVE_DATA      = FALSE

RUN_NEW_CUBIC_MODELS  = FALSE
RUN_NEW_LINEAR_MODELS = FALSE

################################################################################

# define the maximum number of classes to run models to:
max_classes_cubic  = 5
max_classes_linear = 5

# define colour scheme values for normal, MCI, and dementia:
cog_colours <- c('#339900', '#FF9326', '#D92121')

# colour schemes for two categories:
blue_orange     = c('#599BC2', '#E08F6B')
blue_orange_sat = c('#0072B2', '#D55E00')
blue_brown      = c('#599BC2', '#CD8969')
blue_brown_sat  = c('#0072B2', '#B85628')

border_colour = '#9A1D2B' # Movement Disorders red

fig_1_width = 8.5;  fig_1_height = 10.0
fig_2_width = 17.5; fig_2_height = 21.5

```

```{r import-packages}
# An NZBRI-only in-house package for importing the latest live data:
if (IMPORT_LIVE_DATA) {
  library(chchpd) # initial install via devtools::install_github('nzbri/chchpd')
}

# tidyverse libraries:
library(readr)       # to read/write locally cached .csv data files
library(dplyr)       # for data manipulation
library(tidyr)       # for fill & pivot_
library(lubridate)   # for date intervals
library(magrittr)    # for the %<>% operator
library(ggplot2)     # for visualisation
library(scales)      # improved labelling in ggplot
library(ggnewscale)  # allow multiple colour scales in ggplot
library(directlabels)# to label lines on plots
library(cowplot)     # combine multiple separate plots in one figure
library(lcmm)        # latent class models
library(parallel)    # for parallel computation
library(huxtable)    # tables that work in Word output
library(knitr)       # for kable pretty tables
library(kableExtra)  # extra kable options
library(papaja)      # for apa_table
library(stringr)     # to manipulate apa_table output

```

```{r import-data}
# evaluated only if the chchpd package has been imported, to 
# access live data sources.
 
if (IMPORT_LIVE_DATA) { # put this here for when not knitting

participants = chchpd::import_participants(anon_id = FALSE) %>% 
    rename(group = participant_group)

sessions = chchpd::import_sessions() %>% 
  # the PDD follow-up sessions were mostly not coded as part of the 
  # Progression study, so gather sessions from both:
  filter(study %in% c('Follow-up', 'PDD Followup')) %>% 
  # but some sessions *were* entered in both studies, so remove any duplicates:
  group_by(session_id) %>% 
  filter(row_number() == 1) %>% 
  # this person's session seems to have a fictitious WTAR score (none should
  # have been gathered on that session, no original can be found, 
  # and the value changes so markedly from the two previous ones that it 
  # results in a separate class just to fit this one person). Can 
  # drop this filter step once the value is removed from the database:
  filter(session_id != '310PDS_2020-03-04')

np = chchpd::import_neuropsyc()
updrs = chchpd::import_motor_scores()

}
```

```{r collate-dataset}
if (IMPORT_LIVE_DATA) {

dat = right_join(participants, sessions, by = 'subject_id') %>%
  left_join(np, by = 'session_id') %>% 
  left_join(updrs, by = 'session_id')

dat = dat %>%
  filter(np_group %in% c('Control', 'PD'), # exclude atypical cases
         !is.na(cognitive_status),         # remove not-yet classified sessions
         !is.na(WTAR)) %>%                
  mutate(group = factor(group, levels = c('Control', 'PD'))) %>% 
  mutate(cognitive_status = factor(cognitive_status, 
                                   levels = c('N', 'MCI', 'D'),
                                   labels = c('Normal', 'MCI', 'Dementia'))) %>% 
  group_by(subject_id) %>% 
  arrange(years_from_baseline) %>%
  mutate(assessment_num = row_number()) %>% 
  mutate(n_sessions = max(assessment_num)) %>% 
  filter(n_sessions > 1) %>% # exclude cases without follow-up
  mutate(ever_demented = 'Dementia' %in% cognitive_status) %>% 
  # to make line colours match the destination point rather than the origin 
	# point, need to use a diagnosis variable that leads the current diagnosis
	# for each person by one step:
	mutate(cognitive_status_lead = lead(cognitive_status)) %>% 
	# this makes the last value for each person NA, which can cause issues. 
	# fill() replaces them with the latest previous diagnosis:
  fill(cognitive_status_lead) %>% 
  mutate(sampling_interval = 
           years_from_baseline - lag(years_from_baseline)) %>% 
  # should be much the same but here to be explicit:
  mutate(wtar_interval = 
           interval(start = lag(session_date), end = session_date)/years(1)) %>% 
  ungroup()

# lcmm insists on access to a numeric subject variable:
dat = dat %>% 
  mutate(subject_id = factor(subject_id)) %>% 
  mutate(subject_id_num = as.integer(subject_id))

# for lcmm we standardise the age to avoid problems with polynomial effects, 
# as per Proust-Lima et al. (2017). Note that we are using the grand mean age at 
# assessment, rather than averaging across some landmark age for each subject. 
# We use the same standardisation for the linear models, so we can compare them.
dat$age_std = (dat$age - mean(dat$age))/10

dat = dat %>% 
  arrange(subject_id_num, age) %>% 
  select(subject_id_num, group,	sex, ethnicity, symptom_onset_age,
         diagnosis_age, education, age, age_std, wtar_interval, group, 
         cognitive_status, cognitive_status_lead, ever_demented, WTAR, MoCA, 
         global_z, attention_domain, executive_domain, visuo_domain,
         learning_memory_domain,	language_domain, H_Y,	Part_III)
         

# store a cached version of the dataset for optional access on subsequent runs 
# of generating this document:
dat %>% write_csv(file = 'data/dat_wtar.csv')

}

# Regardless of whether IMPORT_LIVE_DATA has been set to TRUE, we import from 
# a cached, static dataset to ensure consistency:
dat = read_csv(file = 'data/dat_wtar.csv') %>% 
  mutate(cognitive_status = factor(cognitive_status, 
                                   levels = c('Normal', 'MCI', 'Dementia')),
         cognitive_status_lead = factor(cognitive_status_lead, 
                                        levels = c('Normal', 'MCI', 'Dementia'))) %>% 
  # divide subjects into three panels in the figure:
  mutate(panel_label = 
           case_when(group == 'Control'     ~ 'Control',
                     ever_demented == FALSE ~ 'PD non-dementia',
                     TRUE                   ~ 'PD dementia'),
         panel_label = 
           factor(panel_label, 
                  levels = c('Control', 'PD non-dementia', 'PD dementia'))) %>% 
  # do this to avoid an issue with lcmm not correctly detecting numeric
  # column types in a tibble:
  as.data.frame()

```

# Introduction

In 2012, the International Parkinson and Movement Disorder Society published its
Task Force guidelines for the diagnosis of mild cognitive impairment in
Parkinson's disease (PD-MCI).[@litvan2012_DiagnosticCriteriaMild] When the
diagnosis is based on a comprehensive battery of multiple individual 
neuropsychological tests, rather than a scale of global cognitive ability, 
significant impairment may be determined in three ways: (i) current performance 
being below appropriate norms, (ii) decline on serial testing, or (iii) decline 
from estimated premorbid levels. The first method tends to predominate in 
current research practice.[@aarsland2021_ParkinsonDiseaseassociatedCognitive] 
The latter two approaches, however, could be advantageous in resolving the 
ambiguity that poor current cognitive function in a given individual might 
reflect long-standing low cognitive ability, rather than a recent 
disease-related deterioration. In practice, however, one seldom has reference to
prior formal serial testing, and so a valid method of estimating premorbid 
function is appealing. The Wechsler Test of Adult Reading (WTAR)[@strauss2006_CompendiumNeuropsychologicalTests] was
proposed in the guidelines as one of two recommended tests to estimate premorbid
functioning (along with the National Adult Reading Test,
NART).[@strauss2006_CompendiumNeuropsychologicalTests] Both tests are based on
the ability to correctly pronounce phonetically-irregular English words, such as
'porpoise' or 'hyperbole'. This ability has been shown to be preserved in the
face of both normal ageing and a number of brain
insults.[@strauss2006_CompendiumNeuropsychologicalTests]
 
When the WTAR was initially normed, it was tested in Parkinson's as well as a
number of other neurological disorders, such as Huntington's, schizophrenia, and
traumatic brain injury. Only in Alzheimer's disease were scores significantly
lower than in matched controls.[@strauss2006_CompendiumNeuropsychologicalTests]
Those results were, however, published in 2001, well before formal MDS
guidelines on diagnosing PD-MCI[@litvan2012_DiagnosticCriteriaMild] and
Parkinson's dementia[@dubois2007_DiagnosticProceduresParkinson] were
promulgated. It is therefore unclear to what extent findings from that original
sample are valid in the face of the significant cognitive deterioration that can
occur in Parkinson's.

We therefore examined WTAR scores in a cognitively well-characterised sample,
spanning the range from normal function through mild cognitive impairment and
dementia. We restricted the sample to participants who had completed a minimum
of two WTARs, so that the trajectory of the measure within individuals over time
could be examined. We used latent class trajectory 
analysis[@proust-lima2017estimation-of-e] to allow for detecting heterogeneous
patterns of change over time within a combined Parkinson's and control sample,
rather than assign participants to _a priori_ sub-groupings.

# Methods

## Participants

```{r descriptives}
descriptives = dat %>% 
  group_by(subject_id_num) %>% 
  mutate(session_num = row_number(),
         n_sessions = max(session_num)) %>% 
  slice_head() %>% # one row per subject
  ungroup()
  
n_group = descriptives %>%
  group_by(group) %>% 
  summarise(n = n(), 
            min_sessions = min(n_sessions),
            mean_sessions = mean(n_sessions),
            sd_sessions = sd(n_sessions),
            max_sessions = max(n_sessions))

n_wtar = descriptives %>% 
  summarise(n = n(), 
            min_sessions = min(n_sessions),
            mean_sessions = mean(n_sessions),
            sd_sessions = sd(n_sessions),
            max_sessions = max(n_sessions),
            total_sessions = sum(n_sessions))

n_ethnicity = descriptives %>% 
  group_by(group, ethnicity) %>% 
  summarise(n = n()) %>% 
  # remove some (currently 3) missing values, which otherwise cause problems:
  drop_na() 

n_pd_with_ethnicity = 
  with(n_ethnicity, sum(n[group == 'PD']))

n_pd_pakeha = 
  with(n_ethnicity, n[group == 'PD' & ethnicity == 'New Zealand European'])

n_pd_maori = 
  with(n_ethnicity, n[group == 'PD' & ethnicity == 'Maori'])

n_pd_samoan = 
  with(n_ethnicity, n[group == 'PD' & ethnicity == 'Samoan'])

n_pd_indian = 
  with(n_ethnicity, n[group == 'PD' & ethnicity == 'Indian'])

n_pd_other = 
  with(n_ethnicity, n[group == 'PD' & ethnicity == 'Other'])

n_control_with_ethnicity = 
  with(n_ethnicity, sum(n[group == 'Control']))

n_control_pakeha = 
  with(n_ethnicity, n[group == 'Control' & ethnicity == 'New Zealand European'])

n_control_other = 
  with(n_ethnicity, n[group == 'Control' & ethnicity == 'Other'])

```

The New Zealand Parkinson's Progression Programme (NZP<sup>3</sup>) is a
longitudinal study of a convenience prevalence sample of idiopathic Parkinson's
participants, largely recruited from the specialist Movement Disorders Clinic at
the New Zealand Brain Research Institute (NZBRI). The study commenced in 2007, 
with recruitment ongoing, and hence covers patients ranging from the
recently-diagnosed to those with advanced disease. Inclusion and exclusion
criteria have been described previously.[@wood2016_DifferentPDMCICriteria] For
this analysis, we selected data from the `r n_group$n[n_group$group =='PD']` 
Parkinson's and `r n_group$n[n_group$group == 'Control']` Control
participants who had completed at least two WTARs (range 2 - 
`r n_wtar$max_sessions`, mean = `r round(n_wtar$mean_sessions, digits = 1)`, 
total number of measures = `r n_wtar$total_sessions`). The period between 
successive WTAR assessments was multi-modal, mostly clustering around intervals 
of one and two years, due to varying follow-up periods over the course of the 
study (see Supplementary Material). Both Parkinson's participants and Controls 
were classified as having normal cognition, mild cognitive impairment, or 
dementia on the basis of a comprehensive Level II neuropsychological 
battery,[@dalrymple-alford2011_CharacterizingMildCognitive;
@wood2016_DifferentPDMCICriteria] administered in accordance with MDS
guidelines.[@dubois2007_DiagnosticProceduresParkinson;
@litvan2012_DiagnosticCriteriaMild] For PD-MCI, this was on the basis of at 
least two test scores falling $\geq$1.5 standard deviations below norms in at
least one cognitive domain. For PD dementia, significant impairments ($\geq$2.0
standard deviations below normative data) in at least two cognitive domains
were required, as well as evidence of significant impairment in everyday
functioning.[@dalrymple-alford2011_CharacterizingMildCognitive;
@wood2016_DifferentPDMCICriteria] The WTAR was not used in the cognitive
diagnostic classification procedure. Characteristics of the sample are shown in
Table \@ref(tab:table-1). Of the `r n_pd_with_ethnicity` Parkinson's 
participants with a recorded ethnicity, `r n_pd_pakeha` 
(`r scales::label_percent(accuracy = 0.1)(n_pd_pakeha/n_pd_with_ethnicity)`) 
were Pākehā (New Zealand European), `r n_pd_maori` were Māori, `r n_pd_samoan` 
was Samoan, `r n_pd_indian` Indian, and `r n_pd_other` were 'Other'. Of the 
Controls, `r n_control_pakeha` 
(`r scales::label_percent(accuracy = 0.1)(n_control_pakeha/n_control_with_ethnicity)`) 
were Pākehā and `r n_control_other` was 'Other'. All participants were speakers 
of New Zealand English, and were assessed against the US norms of the WTAR, 
corrected for age, sex, and years of education (the provided ethnicity 
classifications are not useful in a New Zealand context and all participants 
were assessed against norms for "Whites"). 

## Latent class trajectory modelling

We fitted latent class trajectory models using the `hlme` function from the
`lcmm` package [@proust-lima2017estimation-of-e] (version 
`r packageVersion('lcmm')`), running in the R statistical environment
[@R-Core-Team_R_2021] (version `r R.version$major`.`r R.version$minor`). The
dependent variable was WTAR-estimated premorbid IQ, initially modelled within
each subject as a polynomial (cubic) function of age, to allow for non-linear
trajectories. The resulting trajectories were close to straight lines (see 
Supplementary Material) so we simplified the models to be a linear function of 
age. The models were not informed by any other variables (such as categorical 
MCI or dementia diagnoses). We fitted five separate models, with the specified 
number of latent classes increasing from 1 to 5. The `gridsearch()` function of 
the `lcmm` package was used to run 500 departures from random initial values 
for each multi-class model, using the one-class model from which to generate the
starting values. The maximum number of iterations within the `hlme()` function 
was set at 1000. Parameters corresponding to the best log-likelihood were used 
as initial values for the final estimation of the 
parameters[@proust-lima2017estimation-of-e]. The optimal model was selected on 
the basis of it converging and having the lowest BIC (Bayesian information 
criterion) value of the five candidates. When reporting values from the chosen 
model, we formed the interval in brackets following the maximum likelihood 
estimate (MLE) by subtracting and adding 1.96 times the standard error given by 
`hlme` to the MLE.


```{r table-1}
table_df = dat %>% 
  group_by(subject_id_num) %>% 
  arrange(age) %>% 
  slice_tail() %>% # last observation per subject
  group_by(group) %>% 
  summarise(n = n(),
            Male   = scales::percent_format(accuracy = 0.1)(sum(sex == 'Male')/n),
            Age = paste0(sprintf('%.1f', mean(age)), ' (', sprintf('%.1f',sd(age)), ')'),
            Education = paste0(sprintf('%.1f', mean(education)), ' (', sprintf('%.1f', sd(education)), ')'),
            WTAR = paste0(sprintf('%.1f', mean(WTAR)), ' (', sprintf('%.1f', sd(WTAR)), ')'),
            Normal = scales::percent_format(accuracy = 0.1)(sum(cognitive_status == 'Normal')/n),
            MCI    = scales::percent_format(accuracy = 0.1)(sum(cognitive_status == 'MCI')/n),
            Dementia = scales::percent_format(accuracy = 0.1)(sum(cognitive_status == 'Dementia')/n)) %>% 
  mutate(n = as.character(n)) %>% 
  pivot_longer(n:Dementia) %>% 
  pivot_wider(names_from = 'group')

table_df %>% 
  mutate(name = case_when(name == 'Age' ~ 'Age (SD)',
                          name == 'Education' ~ 'Years of education (SD)',
                          name == 'WTAR' ~ 'WTAR (SD)',
                          name == 'Normal'    ~ 'Normal cognition',
                          TRUE                ~ name)) %>% 
  rename(' '           = name,
         "Parkinson's" = PD) %>%
  apa_table(caption = "Demographics of the Parkinson's and Control groups, and cognitive status at their latest assessment.", align = 'lrr')

```


## Reproducibility

The code and anonymised dataset extracts sufficient to reproduce the analyses
and generate this manuscript are publicly available at
[github.com/nzbri/wtar-trajectory](https://github.com/nzbri/wtar-trajectory).
There are a number of decisions that can affect the outcome of a latent class
modelling analysis and therefore in the Supplementary Material we report against
the 16-item checklist "Guidelines for Reporting on Latent Trajectory
Studies".[@van_de_schoot_grolts-checklist_2017]

# Results

```{r wtar-modelling-cubic, include=FALSE}

# prepare list to hold models with 1 through max_classes_cubic classes:
cubic_models = list()

if (RUN_NEW_CUBIC_MODELS) {

  # currently have to coerce data to a dataframe (done above), as tibbles lead
  # to a bug with the subject id column not being accepted by lcmm as numeric.
  
  # use the 1-class model to set initial start values:
  cubic_models[[1]] <- 
    lcmm::hlme(WTAR ~ poly(age_std, degree = 3, raw = TRUE), 
               random = ~1 + poly(age_std, degree = 3, raw = TRUE),
               subject = 'subject_id_num', ng = 1, data = dat)
  saveRDS(cubic_models[[1]], 'models/cubic_WTAR_1.RDS') # cache to disk
  
  # for each higher-class model, run with 5000 random starts based on the
  # initial one-class model, then run the selected one up to 1000 times to
  # (hopeful) convergence:
  
  for (class_num in 2:max_classes_cubic) {
    
    print(class_num)

    # make use of parallel computation to speed up working through the large 
    # number of iterations to be used for each model. Needs to be done within
    # the loop to work around an issue when knitting in R Markdown with the
    # generation of random numbers in the parallel package:
    num_cores = parallel::detectCores()
    cl = parallel::makeCluster(num_cores)
    
    # need to explicitly pass some variables to the namespace of each process,
    # or the gridsearch and hlme functions below will trip up by not "knowing"
    # some of their parameters:
    parallel::clusterExport(cl, c('class_num', 'cubic_models'))
    
    cubic_models[[class_num]] <-
      lcmm::gridsearch(rep = 500, maxiter = 100, minit = cubic_models[[1]], cl = cl,
                       hlme(WTAR ~ poly(age_std, degree = 3, raw = TRUE), 
                            random = ~1 + poly(age_std, degree = 3, raw = TRUE), 
                            ng = class_num, nwg = TRUE, maxiter = 1000,
                            mixture = ~ poly(age_std, degree = 3, raw = TRUE),
                            subject = 'subject_id_num', data = dat))
    
    parallel::stopCluster(cl)
    
    saveRDS(cubic_models[[class_num]], paste0('models/cubic_WTAR_', 
                                              class_num, '.RDS'))
  }
  
} else { # use previously-computed cubic models:
  
  for (class_num in 1:max_classes_cubic) {
    cubic_models[[class_num]] = readRDS(paste0('models/cubic_WTAR_', 
                                               class_num, '.RDS'))
  }
}

cubic_WTAR_model_table = 
  summarytable(cubic_models[[1]], cubic_models[[2]], cubic_models[[3]], 
               cubic_models[[4]], cubic_models[[5]],
               which = c('G', 'loglik', 'conv', 'BIC', 'entropy', 
                         '%class')) %>% 
  as_tibble() %>% 
  mutate(conv = factor(conv, levels = c(1, 2, 3, 4, 5),
                       labels = c('yes', 'no', '', 'optimisation problem', 
                                  'optimisation problem'))) %>% 
  rename(converged = conv)

# manually select model, on the basis of one that converged & had lowest BIC:
chosen_cubic_classes = 1
chosen_cubic_model   = cubic_models[[chosen_cubic_classes]]

# create a vector of ages to predict against, centred on the mean across all
# sessions, and in decades rather than years to limit polynomial instabilities):
mean_age = mean(dat$age) 
new_data_cubic = 
  data.frame(age = seq(from = 43, to = 89, by = 0.5)) %>% 
  mutate(age_std = (age - mean_age)/10)

# create a dataframe that contains predictions for all candidate models
# (will be used in the supplementary material).
predictions = list()

for (i in 1:max_classes_cubic) {
  prediction = lcmm::predictY(cubic_models[[i]], newdata = new_data_cubic, 
                              var.time = 'age_std', draws = TRUE)
  predictions[[i]] = 
    as.data.frame(prediction$pred) %>% # extract just the predicted values
    cbind(new_data_cubic) # and add in the corresponding age values
  predictions[[i]]$ng = i  # and label with the number of classes
}

# the first one needs to be modified so that it can act as the template to 
# row bind to the others:
predictions[[1]] = predictions[[1]] %>% # add a suffix to the variable names
  rename('Ypred_class1' = 'Ypred', 
         'lower.Ypred_class1' = 'lower.Ypred', 
         'upper.Ypred_class1' = 'upper.Ypred') %>% 
  select(ng, age, age_std, everything()) # set order for the resulting dataframe

cubic_predictions = bind_rows(predictions[1:5]) %>% 
  # reshape to allow ggplotting:
  pivot_longer(cols = Ypred_class1:last_col(), 
               names_to = c('line', 'class'), names_sep = '_',
               values_to = 'predicted_WTAR') %>% 
  pivot_wider(names_from = line, values_from = predicted_WTAR) %>% 
  filter(!is.na(Ypred)) %>% 
  arrange(ng, class, age)

```

```{r wtar-modelling-linear, include=FALSE}

# prepare list to hold models with 1 through max_classes_linear classes:
linear_models = list()

if (RUN_NEW_LINEAR_MODELS) {
  
  # currently have to coerce data to a dataframe (done above), as tibbles lead 
  # to a bug with the subject id column not being accepted by lcmm as numeric.
  
  # use the 1-class model to set initial start values:
  linear_models[[1]] <- 
    lcmm::hlme(WTAR ~ age_std, 
               random = ~1 + age_std,
               subject = 'subject_id_num', ng = 1, data = dat)
  saveRDS(linear_models[[1]], 'models/linear_WTAR_1.RDS') # cache to disk
  
  # for each higher-class model, run with 5000 random starts based on the
  # initial one-class model, then run the selected one up to 1000 times to
  # (hopeful) convergence:
  
  for (class_num in 2:max_classes_linear) {
    
    print(class_num)
    
    # make use of parallel computation to speed up working through the large 
    # number of iterations to be used for each model. Needs to be done within
    # the loop to work around an issue when knitting in R Markdown with the
    # generation of random numbers in the parallel package:
    num_cores = parallel::detectCores()
    cl = parallel::makeCluster(num_cores)
    
    # need to explicitly pass some variables to the namespace of each process, 
    # or the gridsearch and hlme functions below will trip up by not "knowing" 
    # some of their parameters:
    parallel::clusterExport(cl, c('class_num', 'linear_models'))
    
    linear_models[[class_num]] <- 
      lcmm::gridsearch(rep = 500, maxiter = 100, minit = linear_models[[1]], 
                       cl = cl,
                       hlme(WTAR ~ age_std, 
                            random = ~1 + age_std, 
                            ng = class_num, nwg = TRUE, 
                            mixture = ~ age_std, maxiter = 1000,
                            subject = 'subject_id_num', data = dat))
    
    parallel::stopCluster(cl)
    
    saveRDS(linear_models[[class_num]], paste0('models/linear_WTAR_', 
                                               class_num, '.RDS'))
  }
  
} else { # use previously-computed linear models:
  
  for (class_num in 1:max_classes_linear) {
    linear_models[[class_num]] = readRDS(paste0('models/linear_WTAR_', 
                                                class_num, '.RDS'))
  }
  
}

linear_WTAR_model_table = 
  summarytable(linear_models[[1]], linear_models[[2]], linear_models[[3]], 
               linear_models[[4]], linear_models[[5]],
               which = c('G', 'loglik', 'conv', 'BIC', 'entropy', 
                         '%class')) %>% 
  as_tibble() %>% 
  mutate(conv = factor(conv, levels = c(1, 2, 3, 4, 5),
                       labels = c('yes', 'no', '', 'optimisation problem', 
                                  'optimisation problem'))) %>% 
  rename(converged = conv) 

# manually select model, on the basis of one that converged & had lowest BIC:
chosen_linear_classes = 2
chosen_linear_model   = linear_models[[chosen_linear_classes]]
coeffs = coef(chosen_linear_model)

# create a vector of ages to predict against, centred on the mean across all
# sessions, and in decades rather than years to be consistent with the cubic 
# modelling where we need to limit instabilities):
mean_age = mean(dat$age) 
new_data_linear = 
  data.frame(age = seq(from = 43, to = 89, by = 0.5)) %>% 
  mutate(age_std = (age - mean_age)/10)

# create a dataframe that contains predictions for all candidate models
predictions = list()

for (i in 1:max_classes_linear) {
  prediction = lcmm::predictY(linear_models[[i]], newdata = new_data_linear, 
                              var.time = 'age_std', draws = TRUE)
  predictions[[i]] = 
    as.data.frame(prediction$pred) %>% # extract just the predicted values
    cbind(new_data_linear) # and add in the corresponding age values
  predictions[[i]]$ng = i  # and label with the number of classes
}

# the first one needs to be modified so that it can act as the template to 
# row bind to the others:
predictions[[1]] = predictions[[1]] %>% # add a suffix to the variable names
  rename('Ypred_class1' = 'Ypred', 
         'lower.Ypred_class1' = 'lower.Ypred', 
         'upper.Ypred_class1' = 'upper.Ypred') %>% 
  select(ng, age, age_std, everything()) # set order for the resulting dataframe

linear_predictions = bind_rows(predictions[1:5]) %>% 
  # reshape to allow ggplotting:
  pivot_longer(cols = Ypred_class1:last_col(), 
               names_to = c('line', 'class'), names_sep = '_',
               values_to = 'predicted_WTAR') %>% 
  pivot_wider(names_from = line, values_from = predicted_WTAR) %>% 
  filter(!is.na(Ypred)) %>% 
  arrange(ng, class, age)
  
chosen_linear_predictions = linear_predictions %>% 
  filter(ng == chosen_linear_classes) %>% 
  mutate(class = 
           factor(class, 
                  levels = c('class2', 'class1'),
                  labels = c('High performers', 'Typical'))) %>% 
  rename(class_for_lines = class)

# link subjects to their assigned classes:
dat_with_classes = dat %>% 
  left_join(chosen_linear_model$pprob, by = 'subject_id_num') %>% 
   mutate(class = 
           factor(class, 
                  levels = c('2', '1'),
                  labels = c('High performers', 'Typical'))) %>% 
  rowwise() %>% 
  mutate(class_probability = max(c(prob1, prob2)))

# get a dataframe with just one row per subject
individuals = dat_with_classes %>% 
  group_by(subject_id_num) %>% arrange(age) %>% 
  slice_tail()

class_proportions = individuals %>% 
  group_by(class) %>% 
  tally() %>%
  mutate(proportion = scales::percent_format(accuracy = 1)(n/sum(n)))

class_proportions_by_group = individuals %>% 
  group_by(group, class) %>% 
  tally() %>% group_by(group) %>% 
  mutate(proportion = scales::percent_format(accuracy = 1)(n/sum(n)))
```

```{r percent-above-100}
above_100 = dat %>%
  mutate(above_100 = WTAR >= 100) |> 
  group_by(group, above_100) %>%
  tally() %>%
  pivot_wider(names_from = above_100, 
              values_from = n, names_prefix = 'above_') %>%
  mutate(proportion = 
           scales::percent_format(accuracy = 0.1)(above_TRUE/(above_FALSE + above_TRUE)))
```

```{r chi-square}
class_n_by_group = individuals %>% 
  group_by(group, class) %>% 
  tally() %>% 
  pivot_wider(names_from = group, values_from = n)

chi = chisq.test(class_n_by_group[, -1])

chi_n_observed = chi$observed
chi_n_expected = chi$expected
chi_p_value = chi$p.value
chi_statistic = chi$statistic
chi_df = chi$parameter

```



```{r formatted-text-results, include=FALSE}

# extract coefficients from model summary:
summary = data.frame(summary(chosen_linear_model))

typical_slope   = summary$coef[row.names(summary) == 'age_std class1']
typical_slope_se  = summary$Se[row.names(summary) == 'age_std class1']
typical_intcpt  = summary$coef[row.names(summary) == 'intercept class1']
typical_intcpt_se = summary$Se[row.names(summary) == 'intercept class1']

high_slope   = summary$coef[row.names(summary) == 'age_std class2']
high_slope_se  = summary$Se[row.names(summary) == 'age_std class2']
high_intcpt  = summary$coef[row.names(summary) == 'intercept class2']
high_intcpt_se = summary$Se[row.names(summary) == 'intercept class2']

# construct strings for the coefficients and intervals:
typical_slope_str = sprintf('%.1f', typical_slope)
high_slope_str    = sprintf('%.1f', high_slope)

typical_intcpt_str = sprintf('%.1f', typical_intcpt)
high_intcpt_str    = sprintf('%.1f', high_intcpt)

typical_slope_intrvl = 
  paste0('[', sprintf('%.1f', typical_slope - typical_slope_se * 1.96), ', ', 
         sprintf('%.1f', typical_slope + typical_slope_se * 1.96), ']')

high_slope_intrvl = 
  paste0('[', sprintf('%.1f', high_slope - high_slope_se * 1.96), ', ', 
         sprintf('%.1f', high_slope + high_slope_se * 1.96), ']')

typical_intcpt_intrvl = 
  paste0('[', sprintf('%.1f', typical_intcpt - typical_intcpt_se * 1.96), ', ', 
         sprintf('%.1f', typical_intcpt + typical_intcpt_se * 1.96), ']')

high_intcpt_intrvl = 
  paste0('[', sprintf('%.1f', high_intcpt - high_intcpt_se * 1.96), ', ', 
         sprintf('%.1f', high_intcpt + high_intcpt_se * 1.96), ']')

```

## Distribution of scores
The distributions of all WTAR-estimated IQ scores fro the Parkinson's and 
Control participants are shown in Figure \@ref(fig:figure-1-histogram). The mean
and SD for each group's latest score is given in Table \@ref(tab:table-1), with
both well above the expected population norm mean IQ score of 100. The 
population distribution of IQ should be symmetrical about 100, yet in our 
sample, `r above_100$proportion[above_100$group == 'PD']` of Parkinson's WTAR 
scores were greater than or equal to 100, as were
`r above_100$proportion[above_100$group == 'Control']` of Control scores.

## Longitudinal trajectories
The raw data showed that WTAR scores were relatively constant over time (Figure
\@ref(fig:figure-2-trajectories)A). This was despite the dramatic decline in 
overall cognitive performance that occurred particularly in those particpants 
who declined to dementia (Figure \@ref(fig:figure-2-trajectories)B). We modelled
WTAR scores as a linear function of age, with repeated measures within 
individuals, fitting candidate models ranging from one to five latent trajectory
classes. We selected the two-class model on the basis of it having the lowest 
BIC value. Full details on the modelling process are provided in the 
Supplementary Material.

We labelled the two resulting trajectory classes 'Typical' and 
'High performers'. Individuals were assigned to the class for which they had the
highest posterior classification probability. The mean assigned probability was 
`r round(mean(individuals$class_probability), digits = 2)` 
(SD `r round(sd(individuals$class_probability), digits = 2)`), with a value of 
0.7 being regarded as acceptable model performance.[@lennon_framework_2018] The 
Typical trajectory captured 
`r with(class_proportions, proportion[class == 'Typical'])` of all 
participants (`r with(class_proportions_by_group, proportion[class == 'Typical' & group == 'PD'])`
of the PD and `r with(class_proportions_by_group, proportion[class == 'Typical' & group == 'Control'])`
of Control participants). The intercept of the Typical trajectory, representing
the estimated WTAR score of a person at the mean age of assessment 
(`r sprintf('%.1f', mean_age)` years) was
`r typical_intcpt_str` `r typical_intcpt_intrvl`. Scores then gently declined 
at a rate of `r typical_slope_str` `r typical_slope_intrvl` points per decade.
The 'High performers' trajectory (capturing the remaining 
`r with(class_proportions, proportion[class == 'High performers'])` 
of all participants) had an intercept of 
`r high_intcpt_str` `r high_intcpt_intrvl`. This trajectory had a slope of 
`r high_slope_str` `r high_slope_intrvl` points per decade (effectively flat).
That is, the trajectories were both relatively stable over time, and were 
separated primarily due to the initial scores of their respective clusters of 
participants. We make no strong claims as to the number of classes - for example
a single trajectory model, somewhat intermediate between the two reported here, 
would also describe the data relatively well, and a single trajectory was the 
optimal model when cubic rather than linear functions were used (see 
Supplementary Material). The key findings are that the trajectories are 
relatively flat, and do not separate performance between the Parkinson's and 
Control participants. 

(ref:fig-1-caption) The distribution of the WTAR-estimated IQ scores across all 
participants, containing at least two observations from each. Observations are 
colour-coded by their cognitive status at each session. Regardless of current 
cognitive status, WTAR scores span the full range. For each group, the 
distribution was skewed well above the population norm mean of 100. 

```{r figure-1-histogram, fig.align='center', fig.cap='(ref:fig-1-caption)', fig.height=fig_1_height/2.54, fig.width=fig_1_width/2.54, warning=FALSE}
figure_1 = dat %>%  
  ggplot(aes(x = WTAR, fill = cognitive_status)) +
  facet_grid(group ~ .) +
  geom_histogram(binwidth = 1, size = 0.25, colour = 'white') + 
  scale_fill_manual(values = cog_colours, name = 'Cognitive status') +
  scale_y_continuous(limits = c(0, 60), expand = expansion(add = 0),
                     breaks = c(0, 20, 40, 60)) +
  labs(title = 'Distribution of WTAR-estimated IQ scores',
       x = NULL, y = NULL) +  theme_bw() +
  theme(plot.title = element_text(face = 'bold', size = 10),
        axis.text = element_text(colour = 'black', size = 8),
        legend.position = c(0.18, 0.395),
        legend.margin = margin(c(0, 1, 0, 1), unit = 'mm'),
        legend.spacing.y = unit(1,'mm'), # spacing between title & items
        legend.key.size = unit(3.0,'mm'), # spacing between items
        legend.title = element_text(face = 'bold', size = 8),
        legend.text = element_text(size = 8),
        panel.spacing = unit(4, 'mm'),
        axis.ticks = element_line(colour = border_colour, size = 0.15),
        panel.grid.major.y = element_line(size = 0.25),
        panel.grid.minor.y = element_blank(),
        panel.grid.major.x = element_blank(),
        panel.grid.minor.x = element_blank(),
        panel.border = element_rect(colour = border_colour, size = 0.25),
        strip.background = 
          element_rect(colour = border_colour, fill = border_colour),
        strip.text = element_text(face = 'bold', colour = 'white', size = 10))

figure_1

ggsave('images/wtar-figure-1-histogram.pdf', 
       width = fig_1_width, height = fig_1_height, units = 'cm')
ggsave('images/wtar-figure-1-histogram.png', 
       width = fig_1_width, height = fig_1_height, units = 'cm', dpi = 600)

```

(ref:fig-2-caption) ***(A)*** Longitudinal WTAR score trajectories for all 
individuals, divided into Controls, Parkinson's participants who remained 
dementia-free, and those who developed dementia. Superimposed are the two 
predicted latent class trajectories (blue ribbon = _High performers_, brown 
ribbon = _Typical_). Blue and brown connecting lines link observations from 
individuals from each class. ***(B)***  Global cognitive z-scores for the 
Parkinson's participants who developed dementia. Their overall cognitive 
performance declined dramatically, in contrast to their relatively stable WTAR 
scores. To illustrate this, two individuals who progressed to dementia are 
highlighted (with larger symbols and thicker connecting lines), showing their 
flat WTAR trajectories but dramatic declines in overall neuropsychological 
z-score. In each panel, current cognitive status is shown as cognitively normal
(green circles), mild cognitive impairment (orange triangles), or dementia (red 
squares). Upon reaching dementia, the WTAR was not assessed again.

```{r figure-2-trajectories, fig.align='center', fig.cap='(ref:fig-2-caption)', fig.height=fig_2_height/2.54, fig.width=fig_2_width/2.54, warning=FALSE}

# select two individuals to highlight in the figure.
# i.e. a person with high initial WTAR who declines to dementia yet 
# retains high WTAR scores. Then highlight that person's z-score data,
# showing substantial decline. Do the same for a person from the other 
# trajectory class, showing a similar pattern.
dat_with_classes_plus_highlights = dat_with_classes %>%
  # we identified the subject id numbers to highlight by temporarily showing 
  # text labels of each subject id in the lower panel:
  mutate(highlight = case_when(subject_id_num %in% c(63, 110) ~ TRUE,
                                                         TRUE ~ FALSE)) %>%
  arrange(highlight, subject_id_num, age)
  
# upper panel, of WTAR scores by age:
figure_2_upper = dat_with_classes_plus_highlights %>% 
  ggplot(aes(x = age)) +
  facet_grid(panel_label ~ .) +
  scale_colour_manual(values = blue_brown_sat, name = 'Class', guide = 'none') + 
  scale_fill_manual(values = blue_brown, name = 'Class', guide = 'none') + 
  scale_shape_manual(values = c(21, 25, 22), name = 'Cognitive status') +
  geom_ribbon(dat = chosen_linear_predictions,
              aes(ymin = lower.Ypred, ymax = upper.Ypred, fill = class_for_lines),
              colour = NA, alpha = 0.2) +
  geom_line(dat = chosen_linear_predictions,
            aes(y = Ypred, colour = class_for_lines), 
            size = 0.25, linetype = 'dashed') +
  scale_size_manual(values = c(0.25, 1.5)) +
  geom_line(aes(y = WTAR, colour = class, group = subject_id_num, 
                size = highlight), alpha = 1.0) +
  # via the ggnewscale package, allows us to have independent colour scales for 
  # the trajectories (2 levels) and the cognitive categories (3 levels):
  new_scale_color() + new_scale_fill() + new_scale('size') +
  scale_colour_manual(values = c('white', 'black')) + 
  scale_fill_manual(values = cog_colours, name = 'Cognitive status') +
  # setting stroke = 0.1 gives nice sharp shapes:
  scale_size_manual(values = c(1.5, 3.0)) +
  geom_point(aes(y = WTAR, fill = cognitive_status, size = highlight,
                 #stroke = highlight,
                 colour = highlight, # minimal border stroke
                 shape = cognitive_status), stroke = 0.2) +
  scale_x_continuous(limits = c(42, 89.9), expand = c(0,0),
                     labels = scales::label_number(suffix = ' years')) +
  scale_y_continuous(limits = c(75, 130), expand = expansion(add = 0)) +
  labs(title = 'A. Longitudinal WTAR scores by group',
       subtitle = 'Shaded bands indicate the two predicted latent class trajectories',
       x = NULL, y = NULL) +
  theme_bw() +
  theme(plot.title = element_text(face = 'bold', size = 9),
        plot.subtitle = element_text(size = 8),
        axis.text = element_text(size = 7, colour = 'black'),
        axis.ticks = element_line(colour = border_colour, size = 0.15),
        panel.grid = element_blank(),
        legend.pos = 'none', #c(0.09, 0.095),
        legend.margin = margin(c(1, 1, 1, 1), unit = 'mm'),
        legend.spacing.y = unit(1, 'mm'), # spacing between title & items
        legend.key.size = unit(2.5, 'mm'), # spacing between items
        legend.title = element_text(face = 'bold', size = 6),
        legend.text = element_text(size = 7),
        panel.spacing = unit(4, 'mm'),
        panel.border = element_rect(colour = border_colour, size = 0.25),
        strip.background = 
          element_rect(colour = border_colour, fill = border_colour),
        strip.text = element_text(face = 'bold', colour = 'white', size = 8))

# lower panel, of z-score trajectories of dementia-converters only:
figure_2_lower = dat_with_classes_plus_highlights %>% 
  filter(panel_label == 'PD dementia') %>% 
  ggplot(aes(x = age, y = global_z)) +
  facet_grid(panel_label ~ .) +
  scale_size_manual(values = c(0.25, 1.5)) +
  scale_colour_manual(values = blue_brown_sat, name = 'Class', guide = 'none') +
  scale_fill_manual(values = cog_colours, name = 'Cognitive status') +
  scale_shape_manual(values = c(21, 25, 22), name = 'Cognitive status') +
  geom_line(aes(group = subject_id_num, colour = class, size = highlight),
            show.legend = FALSE) +
  # use ggscale to have independent size scales:
  new_scale_colour() + new_scale('size') +
  scale_size_manual(values = c(1.5, 3.0), guide = 'none') +
  scale_colour_manual(values = c('white', 'black'), guide = 'none') +
  # setting stroke = 0.1 gives nice sharp shapes:
  geom_point(aes(fill = cognitive_status, size = highlight,
                 colour = highlight, # minimal border stroke
                 shape = cognitive_status), stroke = 0.2) +
  # temporarily enable this to allow identifying subjects to highlight:
  #geom_text(aes(label = subject_id_num)) + 
  scale_x_continuous(limits = c(42, 89.9), expand = c(0,0),
                     labels = scales::label_number(suffix = ' years')) +
  labs(title = 'B. Global cognitive z-scores',
       subtitle = 'Of those PD participants who developed dementia',
       x = NULL, y = NULL) + 
  theme_bw() +
  theme(plot.title = element_text(face = 'bold', size = 9),
        plot.subtitle = element_text(size = 8),
        axis.ticks = element_line(colour = border_colour, size = 0.15),
        axis.text = element_text(size = 7, colour = 'black'),
        panel.grid = element_blank(),
        legend.position = c(0.085, 0.46), # 0.64 puts it in the top panel
        legend.margin = margin(c(1, 1, 1, 1), unit = 'mm'),
        legend.spacing.y = unit(1,'mm'), # spacing between title & items
        legend.key.size = unit(3.0,'mm'), # spacing between items
        legend.title = element_text(face = 'bold', size = 7),
        legend.text = element_text(size = 7),
        panel.border = element_rect(colour = border_colour, size = 0.25),
        strip.background = 
          element_rect(colour = border_colour, fill = border_colour),
        strip.text = element_text(face = 'bold', colour = 'white', size = 8))

figure_2 = 
  cowplot::plot_grid(figure_2_upper, figure_2_lower, nrow = 2, 
                     axis = 'l', align = 'v', rel_heights = c(1.0, 0.388))

figure_2

ggsave('images/wtar-figure-2-trajectories.pdf', 
       width = fig_2_width, height = fig_2_height, units = 'cm')
ggsave('images/wtar-figure-2-trajectories.png', 
       width = fig_2_width, height = fig_2_height, units = 'cm', dpi = 600)
```

# Discussion

Unlike in Alzheimer's disease, we found that WTAR scores were stable over time
in Parkinson's, despite many of our participants undergoing substantial
cognitive decline over the course of the study (Figure
\@ref(fig:figure-2-trajectories)B). Latent class analysis revealed that in our
particular sample, people fell into one of two trajectory classes, but these
appeared to be largely driven by two clusters of performance at
baseline, rather than being trajectories that meaningfully differed 
longitudinally. Those with very high initial WTAR scores (the "High performers" 
class) maintained near-ceiling performance levels (Figure 
\@ref(fig:figure-2-trajectories)A), even if they subsequently developed dementia
(Figure \@ref(fig:figure-2-trajectories)B). The remaining 
`r with(class_proportions, proportion[class == 'Typical'])` of participants (the
"Typical" class) had a wider range of initial scores, but were again relatively
stable, with an estimated decline of only `r typical_slope_str` points per 
decade.

Measures of premorbid function are closely tied to the concept of 
cognitive reserve.[@stern2012_CognitiveReserveAgeing] For example, higher NART
scores have been associated with better neuropsychological test performance in 
people with Parkinson's,[@koerts2013_InfluenceCognitiveReserve] indicating that
higher cognitive reserve may be protective against subsequent cognitive decline. 
This can lead to circular reasoning if the premorbid measure is not reliable,
however: if the disease process reduces current performance on that measure, 
then the inference of poorer cognitive reserve would not be valid. Our findings,
of stable scores despite substantial cognitive decline, support the WTAR as a
stable indicator of cognitive reserve in Parkinson's.

There are reservations about the use of the WTAR, however. Although still in
wide use, it is outdated, inasmuch as it was originally devised to estimate IQ
scores from the WAIS-III (Wechsler Adult Intelligence Scale, released in 1997).
That has been superseded by the WAIS-IV (2008), and in turn, the WAIS-V is 
currently under development. The TOPF (Test of Premorbid Function) estimates 
WAIS-IV IQ and was designed as a successor to the WTAR, but has had limited
uptake.[@bright2020_ComparisonMethodsEstimating] The age of an IQ-related test 
is important: the Flynn effect[@flynn1999_SearchingJusticeDiscovery] is the 
robust finding that cohort IQ scores increase substantially over time (by up to 
1 standard deviation per generation). Our sample would have been born 
approximately a generation after their age-matched WAIS-III normative sample 
group and that might explain their above-average estimated IQ levels. Another 
possibility is that by virtue of volunteering for research, our sample is 
simply non-representative of the population at large. Such a self-selection 
effect should, however, (i) apply more to the controls than to the Parkinson's 
group, which did not seem to be the case, and (ii) also affect most other 
research samples. With cognitive decline, the other neuropsychological test 
scores did decrease below population norms. If the WTAR was used as an 
individualised premorbid reference for those scores, rather than a z-score norm 
of zero, we would expect to see inflated proportions classified as MCI and PDD. 
This does indeed seem to occur[@marras2013_MeasuringMildCognitive] (see 
discussion below).

The WTAR (and NART) are also limited in that they are inherently tied to 
peculiarities of written and spoken English. The orthography (writing system)
of a language can be described as deep/opaque when it contains many 
irregularities in its mappings of graphemes to phonemes, or shallow/transparent
when the mappings are largely regular.[@frost1987_StrategiesVisualWord] In a 
quantitative analysis of 17 orthographies,[@marjou2021_OTEANNEstimatingTransparency]
the reading of English words stood out as particularly opaque, while by 
comparison Arabic, Finnish, Korean, Serbo-Croatian, and Turkish were highly 
transparent. Attempting to devise analogues of tests like the WTAR for
speakers of languages with transparent orthographies is unlikely to be fruitful.

Even across varieties of English, both between and within countries, the US- and
UK-based selection of words can be problematic. For example, the TOPF was found 
to not reliably predict WAIS-IV IQ in New Zealand English speakers of Māori 
ethnicity.[@dudley2017_TestPremorbidFunctioning] A word like 'porpoise', ranked 
as relatively simple (28 out of 70), resulted in more errors than a word like 
'plethora' (ranked 42 out of 70), likely reflecting different word frequencies 
between North American and New Zealand English. After the commencement of our 
study, a New Zealand Adult Reading Test (NZART) was 
created[@starkey2011_DevelopmentNewZealand], with a more culturally-relevant 
selection of words, but this will require further development to supplant the 
established international tests. Neuropsychological screening tests developed in
the "Anglosphere" have been shown to have poor cross-cultural validity in Parkinson's.[@statucka2021_MulticulturalismChallengeCognitive] This 
extends even to visuoperceptual and non-verbal executive tasks previously 
assumed to be "culture fair".[@statucka2019_OriginsMatterCulture] It is perhaps
therefore not surprising that an inherently linguistic test faces issues with
cross-cultural applicability. In subsequent revisions of the PD-MCI diagnostic 
criteria, if premorbid measures continue to be advocated, more consideration 
could be given to alternative 
techniques[@franzen1997_MethodsEstimatingPremorbid] that could be valid in a 
wider international and cross-cultural context.

The PD-MCI guidelines do not actually formalise how the results of premorbid
function tests should be used in practice to demonstrate decline in cognitive
functioning.[@marras2014_ToolsTradeState; @geurtsen2014_ParkinsonDiseaseMild] 
We are aware of only one study[@marras2013_MeasuringMildCognitive] that has 
compared the norms-based vs premorbid estimation approaches to establishing
cognitive impairment. They converted the WTAR-estimated full-scale IQ to a 
z-score and used that as the reference against which to test each individual 
neuropsychological test z-score, with a test that was lower by more than 1.5 SD
deemed impaired. Of their sample of 139 non-demented people with Parkinson's, 
the WTAR method classified many more of them as having PD-MCI (79%) than did a
norms-based Level II classification method (33%). Marras _et al._ 
interpreted this as evidence that most people with Parkinson's have undergone at
least some decline relative to their premorbid function. Conversely it might be
that the WTAR simply over-estimated that premorbid level of function - just as 
in our sample, where the distribution of estimated IQ values was well above the 
supposed population mean of 100.

In summary, WTAR is a measure that is exceptionally stable in Parkinson's, 
even in the presence of a substantial decline in current cognitive functioning. 
This can make it a valid research tool to probe cognitive reserve and premorbid 
function differences across groups. In absolute terms, however, it appears to 
overestimate premorbid IQ, making it unsuitable to establish a decline in 
function within individuals. All such measures may suffer from cross-cultural 
word choice issues even across different varieties of English. Analogous tests 
are not able to be created in languages that do not share the orthigraphic 
peculiarities of English. Hence in order to be valid in an international 
context, we recommend that in future revisions of MDS guidelines, tests of 
premorbid function like the WTAR no longer be advocated as one of the means of 
formally establishing cognitive decline at an individual level in Parkinson's.

# References


