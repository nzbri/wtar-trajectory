---
title: The Wechsler Test of Adult Reading is a stable measure of premorbid cognitive
  function in Parkinson's
author:
- name: Kyla-Louise Horne, PhD
  affiliation: '1'
- name: Reza Shoorangiz, PhD
  affiliation: '1,2,3'
- name: Daniel J. Myall, PhD
  affiliation: '1'
- name: Tim J. Anderson, MD, FRACP
  affiliation: '1,2,4'
- name: John C. Dalrymple-Alford, PhD
  affiliation: '1,2,5'
- name: Michael R. MacAskill, PhD
  affiliation: '1,2'
  corresponding: yes
  address: 66 Stewart St, Christchurch 8011, New Zealand
  email: michael.macaskill@nzbri.org
shorttitle: Parkinson's premorbid function
output:
  papaja::apa6_word:
  papaja::apa6_pdf:
link-citations: yes
csl: format/sage-vancouver.csl
bibliography: format/wtar-references.bib
appendix: 2021-wtar-supplementary.Rmd
linenumbers: yes
mask: no
draft: no
documentclass: apa6
classoption: man
affiliation:
- id: '1'
  institution: New Zealand Brain Research Institute, 66 Stewart St, Christchurch,
    New Zealand
- id: '2'
  institution: Department of Medicine, University of Otago, Christchurch; Christchurch,
    New Zealand
- id: '3'
  institution: Department of Electrical and Computer Engineering, University of Canterbury,
    Christchurch, New Zealand
- id: '4'
  institution: Department of Neurology, Christchurch Hospital, Christchurch, New Zealand
- id: '5'
  institution: School of Psychology, Speech, and Hearing, University of Canterbury,
    Christchurch, New Zealand
abstract: Background. A measure of premorbid cognitive function 
  such as the WechslerTest of Adult Reading (WTAR) is recommended to be 
  considered when determining the current cognitive status of people with 
  Parkinson's disease. WTAR scores are known to decline in Alzheimer's disease, 
  however, and it has not been formally demonstrated that they remain stable in 
  spite of the cognitive deterioration that occurs in Parkinson's. 
  Objectives. Assess long-term trajectories of WTAR scores in people with 
  Parkinson's as a function of age. Methods. From 253 Parkinson's and 57 
  Control participants who had completed at least two WTARs, we analysed scores
  using latent class trajectory analysis. Results. WTAR was stable in this 
  sample. Conclusion. The WTAR is a stable measure of premorbid function 
  despite the substantial cognitive decline exhibited by many of the 
  participants.
keywords: Parkinson disease, cognitive impairment, dementia, neuropsychology
wordcount: 'Abstract: up to 150, main body: up to 1700'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = FALSE,
	message = FALSE,
	warning = FALSE
)
options(knitr.kable.NA = '')
```

```{r define-variables}
################################################################################
### 1. To save time taken by re-importing live data online everytime this  
###    document is generated, set the following variable to be FALSE. This will 
###    instead import static values from a locally-cached file.
### 2. Eventually, an anonymised cached version of the dataset(s) will be 
###    distributed publicly with these files, so that external (non-NZBRI) users
###    can also generate and alter the document, without needing the live data 
###    import functions provided by the in-house `chchpd` package.
### 3. We also can choose not to re-compute the latent class models on each run,
###    and instead use cached model objects to save re-computing them each time.
################################################################################
IMPORT_LIVE_DATA = FALSE

RUN_NEW_CUBIC_MODELS  = FALSE
RUN_NEW_LINEAR_MODELS = FALSE

################################################################################

# define the maximum number of classes to run models to:
max_classes_cubic = 5
max_classes_linear = 5

# define colour scheme values for normal, MCI, and dementia:
cog_colours <- c('#339900', '#FF9326', '#D92121')

# colour schemes for two categories (e.g. male/female):
orange_blue = c('#D55E00', '#0072B2')
blue_orange = c('#599BC2', '#E08F6B')
blue_orange_sat = c('#0072B2', '#D55E00')

fig_1_width = 17.5;   fig_1_height = 16.5

```

```{r import-packages}
# An NZBRI-only in-house package for importing the latest live data:
if (IMPORT_LIVE_DATA) {
  library(chchpd) # initial install via devtools::install_github('nzbri/chchpd')
}

# tidyverse libraries:
library(readr)       # to read/write locally cached .csv data files
library(dplyr)       # for data manipulation
library(tidyr)       # for fill & pivot_
library(lubridate)   # for date intervals
library(magrittr)    # for the %<>% operator
library(ggplot2)     # for visualisation
library(scales)      # improved labelling in ggplot
library(ggnewscale)  # allow multiple colour scales in ggplot
library(directlabels)# to label lines on plots
library(cowplot)     # combine multiple separate plots in one figure
library(lcmm)        # latent class models
library(parallel)    # for parallel computation
library(huxtable)    # tables that work in Word output
library(knitr)       # for kable pretty tables
library(kableExtra)  # extra kable options
library(papaja)      # for apa_table

```

```{r import-data}
# evaluated only if the chchpd package has been imported, to 
# access live data sources.
 
if (IMPORT_LIVE_DATA) { # put this here for when not knitting

participants = chchpd::import_participants(anon_id = FALSE) %>% 
    rename(group = participant_group)

sessions = chchpd::import_sessions() %>% 
  # the PDD follow-up sessions were mostly not coded as part of the 
  # Progression study, so gather sessions from both:
  filter(study %in% c('Follow-up', 'PDD Followup')) %>% 
  # but some sessions *were* entered in both studies, so remove any duplicates:
  group_by(session_id) %>% 
  filter(row_number() == 1) %>% 
  # this person's session seems to have a fictitious WTAR score (none should
  # have been gathered on that session, no original can be found, 
  # and the value changes so markedly from the two previous ones that it 
  # results in a separate class just to fit this one person). Can 
  # drop this filter step once the value is removed from the database:
  filter(session_id != '310PDS_2020-03-04')

np = chchpd::import_neuropsyc()
updrs = chchpd::import_motor_scores()

}
```

```{r collate-dataset}
if (IMPORT_LIVE_DATA) {

dat = right_join(participants, sessions, by = 'subject_id') %>%
  left_join(np, by = 'session_id') %>% 
  left_join(updrs, by = 'session_id')

dat = dat %>%
  filter(np_group %in% c('Control', 'PD'), # exclude atypical cases
         !is.na(cognitive_status),         # remove not-yet classified sessions
         !is.na(WTAR)) %>%                
  mutate(group = factor(group, levels = c('Control', 'PD'))) %>% 
  mutate(cognitive_status = factor(cognitive_status, 
                                   levels = c('N', 'MCI', 'D'),
                                   labels = c('Normal', 'MCI', 'Dementia'))) %>% 
  group_by(subject_id) %>% 
  arrange(years_from_baseline) %>%
  mutate(assessment_num = row_number()) %>% 
  mutate(n_sessions = max(assessment_num)) %>% 
  filter(n_sessions > 1) %>% # exclude cases without follow-up
  mutate(ever_demented = 'Dementia' %in% cognitive_status) %>% 
  # to make line colours match the destination point rather than the origin 
	# point, need to use a diagnosis variable that leads the current diagnosis
	# for each person by one step:
	mutate(cognitive_status_lead = lead(cognitive_status)) %>% 
	# this makes the last value for each person NA, which can cause issues. 
	# fill() replaces them with the latest previous diagnosis:
  fill(cognitive_status_lead) %>% 
  mutate(sampling_interval = 
           years_from_baseline - lag(years_from_baseline)) %>% 
  # should be much the same but here to be explicit:
  mutate(wtar_interval = 
           interval(start = lag(session_date), end = session_date)/years(1)) %>% 
  ungroup()


# lcmm insists on access to a numeric subject variable:
dat = dat %>% 
  mutate(subject_id = factor(subject_id)) %>% 
  mutate(subject_id_num = as.integer(subject_id))

# for lcmm we standardise the age to avoid problems with polynomial effects, 
# as per Proust-Lima et al. (2017). Note that we are using the grand mean age at 
# assessment, rather than averaging across some landmark age for each subject. 
# We use the same standardisation for the linear models, so we can compare them.
dat$age_std = (dat$age - mean(dat$age))/10

dat = dat %>% 
  arrange(subject_id_num, age) %>% 
  select(subject_id_num, group,	sex, symptom_onset_age,	diagnosis_age,
         education, age, age_std, wtar_interval, group, cognitive_status, 
         cognitive_status_lead, ever_demented, WTAR, MoCA, global_z, 
         attention_domain, executive_domain, visuo_domain,
         learning_memory_domain,	language_domain, H_Y,	Part_III)
         

# store a cached version of the dataset for optional access on subsequent runs 
# of generating this document:
dat %>% write_csv(file = 'data/dat_wtar.csv')

}

# Regardless of whether IMPORT_LIVE_DATA has been set to TRUE, we import from 
# a cached, static dataset rather to ensure consistency:
dat = read_csv(file = 'data/dat_wtar.csv') %>% 
  mutate(cognitive_status = factor(cognitive_status, 
                                   levels = c('Normal', 'MCI', 'Dementia')),
         cognitive_status_lead = factor(cognitive_status_lead, 
                                        levels = c('Normal', 'MCI', 'Dementia'))) %>% 
  # divide subjects into three panels in the figure:
  mutate(panel_label = 
           case_when(group == 'Control'     ~ 'Control',
                     ever_demented == FALSE ~ 'PD non-dementia',
                     TRUE                   ~ 'PD dementia'),
         panel_label = 
           factor(panel_label, 
                  levels = c('Control', 'PD non-dementia', 'PD dementia'))) %>% 
  # do this to avoid an issue with lcmm not correctly detecting numeric
  # column types in a tibble:
  as.data.frame()

```

# Introduction

In 2012, the International Parkinson and Movement Disorder Society published its Taskforce guidelines for the diagnosis of mild cognitive impairment in Parkinson's disease (PD-MCI).[@litvan2012_DiagnosticCriteriaMild] When the diagnosis is based on specific (rather than global) neuropsychological tests, significant impairment may be determined in three ways: (i) performance below appropriate norms, or (ii) decline on serial testing, or (iii) decline from estimated premorbid levels. The latter two approaches could be advantageous in resolving the ambiguity that poor current cognitive function might reflect long-standing low cognitive ability, rather than a recent disease-related deterioration. In practice, however, one seldom has reference to prior formal serial testing, and so a valid method of estimating premorbid function is appealing. The Wechsler Test of Adult Reading (WTAR) was proposed in the guidelines as one of two recommended tests to estimate premorbid functioning (along with the National Adult Reading Test, NART). Both tests are based on being able to recognise and pronounce irregularly-spelled English words. ***[TODO: give some examples]*** This ability has been shown to be preserved in the face of both normal ageing and a number of brain insults[@strauss2006_CompendiumNeuropsychologicalTests].

When the test was initially normed, it was tested in Parkinson's as well as a number of other neurological disorders, such as Huntington's, schizophrenia, and traumatic brain injury. Only in Alzheimer's disease were the scores significantly lower than in matched controls.[@strauss2006_CompendiumNeuropsychologicalTests] ***[TODO - read and insert reference to the Wechsler manual]***. Those results were published in 2001, well before the current guidelines on diagnosing PD-MCI[@litvan2012_DiagnosticCriteriaMild] and Parkinson's dementia[@dubois2007_DiagnosticProceduresParkinson] were promulgated. It is therefore unclear to what extent those original findings are valid in the face of the significant cognitive deterioration that can occur in Parkinson's.

We therefore firstly sought to examine WTAR scores in a cognitively well-characterised sample, spanning the range from normal function through mild cognitive impairment to dementia. Secondly, we restricted the sample to participants who had completed a minimum of two WTARs, so that the stability of the measure within individuals over time could be examined.    

# Methods

```{r descriptives}
group_n = dat %>% 
  group_by(subject_id_num) %>% 
  mutate(session_num = row_number(),
         n_sessions = max(session_num)) %>% 
  slice_head() %>% # one row per subject
  group_by(group) %>% 
  summarise(n = n(), 
            min_sessions = min(n_sessions),
            mean_sessions = mean(n_sessions),
            sd_sessions = sd(n_sessions),
            max_sessions = max(n_sessions))

wtar_n = dat %>% 
  group_by(subject_id_num) %>% 
  mutate(session_num = row_number(),
         n_sessions = max(session_num)) %>% 
  slice_head() %>% # one row per subject
  ungroup() %>% 
  summarise(n = n(), 
            min_sessions = min(n_sessions),
            mean_sessions = mean(n_sessions),
            sd_sessions = sd(n_sessions),
            max_sessions = max(n_sessions),
            total_sessions = sum(n_sessions))

```

The New Zealand Parkinson's Progression Programme (NZP<sup>3</sup>) is a longitudinal study of a convenience prevalence sample of idiopathic Parkinson's, largely recruited from the specialist Movement Disorders Clinic at the New Zealand Brain Research Institute. The study commenced in 2007, with recruitment ongoing, and hence covers patients ranging from the recently-diagnosed to those with advanced disease. Inclusion and exclusion criteria have been described previously [@wood2016_DifferentPDMCICriteria]. For this analysis, we selected data only from the `r group_n$n[group_n$group == 'PD']` Parkinson's and `r group_n$n[group_n$group == 'Control']` Control participants who had completed at least two WTARs (range 2 - `r wtar_n$max_sessions`, mean = `r wtar_n$mean_sessions`, total number of measures = `r wtar_n$total_sessions`). The period between successive WTAR assessments was multi-modal, mostly clustering around intervals of one and two years, due to varying follow-up periods over the course of the study. Both patients and controls were classified as having normal cognition, mild cognitive impairment, or dementia on the basis of a comprehensive neuropsychological battery[@dalrymple-alford2011_CharacterizingMildCognitive; @wood2016_DifferentPDMCICriteria], administered in accordance with MDS guidelines[@dubois2007_DiagnosticProceduresParkinson; @litvan2012_DiagnosticCriteriaMild]. Although the WTAR was assessed during each session, we did not actually use it in the diagnostic classification process: this was done on the basis of test scores falling below 1.5 standard deviations of norms,[@dalrymple-alford2011_CharacterizingMildCognitive; @wood2016_DifferentPDMCICriteria] rather than being compared to an estimated pre-morbid level. Characteristics of the sample are shown in Table \@ref(tab:table-1). All participants were speakers of New Zealand English, and were assessed against the ***TODO:*** UK? norms of the WTAR, corrected for age, sex, and years of education. ***{TODO: Kyla to confirm UK norms, and any other relevant details.]***

## Latent class trajectory modelling

We fitted latent class trajectory models using the $hlme$ function from the $lcmm$ package [@proust-lima_estimation_2017] (version `r packageVersion('lcmm')`), running in the R statistical environment [@R-Core-Team_R_2021] (version `r R.version$major`.`r R.version$minor`). The dependent variable was WTAR estimated IQ, initially modelled within each subject as a polynomial (cubic) function of age, to allow for non-linear trajectories. The resulting trajectories were close to straight lines and thus we simplified the models to be a linear function of age. The models were unaware of any other variables (such as categorical MCI or dementia diagnoses). We fitted five separate models, with the specified number of latent classes increasing from 1 to 5. The model with just one latent class was used to provide starting values for the subsequent models with multiple classes. The `gridsearch()` function of the `lcmm` package was used to run 5000 departures from random initial values for each multi-class model, using the one-class model to generate those starting values from. The maximum number of iterations within the `hlme()` function was set at 1000. ***Check with Daniel & Reza on the phrasing of this process.*** Parameters corresponding to the best log-likelihood were used as initial values for the final estimation of the parameters [@proust-lima_estimation_2017]. Selection of the optimal model was on the basis of selecting the one with the lowest BIC value.

```{r table-1}
table_df = dat %>% 
  group_by(subject_id_num) %>% 
  arrange(age) %>% 
  slice_tail() %>% # last observation per subject
  group_by(group) %>% 
  summarise(n = n(),
            Male   = scales::percent_format(accuracy = 0.1)(sum(sex == 'Male')/n),
            Age = paste0(sprintf('%.1f', mean(age)), ' (', sprintf('%.1f',sd(age)), ')'),
            Education = paste0(sprintf('%.1f', mean(education)), ' (', sprintf('%.1f', sd(education)), ')'),
            WTAR = paste0(sprintf('%.1f', mean(WTAR)), ' (', sprintf('%.1f', sd(WTAR)), ')'),
            Normal = scales::percent_format(accuracy = 0.1)(sum(cognitive_status == 'Normal')/n),
            MCI    = scales::percent_format(accuracy = 0.1)(sum(cognitive_status == 'MCI')/n),
            Dementia = scales::percent_format(accuracy = 0.1)(sum(cognitive_status == 'Dementia')/n)) %>% 
  mutate(n = as.character(n)) %>% 
  pivot_longer(n:Dementia) %>% 
  pivot_wider(names_from = 'group')

table_df %>% 
  mutate(name = case_when(name == 'Education' ~ 'Education (years)',
                          name == 'Normal'    ~ 'Normal cognition',
                          TRUE                ~ name)) %>% 
  rename(' '           = name,
         "Parkinson's" = PD) %>%
  apa_table(caption = "Demographics of the Parkinson's and Control groups, as at their latest assessment.", align = 'lrr') #%>% 
  # kable(caption = "Demographics of the Parkinson's and Control groups, as at their latest assessment.", align = 'lrr') %>% #, vline = '')#, booktabs = TRUE) %>%
  #kable_styling(position = 'center') %>%
  #row_spec(0, bold = TRUE)

```


## Reproducibility

The code and anonymised dataset extracts sufficient to reproduce the analyses and generate this manuscript are publicly available at [github.com/nzbri/wtar-trajectory](https://github.com/nzbri/wtar-trajectory). There are a number of decisions that can affect the outcome of a latent class modelling analysis and therefore in the Supplementary Material we report against the 16-item checklist "Guidelines for Reporting on Latent Trajectory Studies".[@van_de_schoot_grolts-checklist_2017]

# Results

```{r wtar-modelling-cubic, include=FALSE}

# prepare list to hold models with 1 through max_classes_cubic classes:
cubic_models = list()

if (RUN_NEW_CUBIC_MODELS) {

  # make use of parallel computation to speed up working through the large number of 
  # iterations to be used for each model:
  num_cores = parallel::detectCores()
  cl = parallel::makeCluster(num_cores)
  
  # currently have to coerce data to a dataframe (done above), as tibbles lead to 
  # a bug with the subject id column not being accepted by lcmm as numeric.
  
  # use the 1-class model to set initial start values:
  cubic_models[[1]] <- lcmm::hlme(WTAR ~ poly(age_std, degree = 3, raw = TRUE), 
                                  random = ~1 + poly(age_std, degree = 3, raw = TRUE),
                                  subject = 'subject_id_num', ng = 1, 
                                  data = dat)
  saveRDS(cubic_models[[1]], 'models/cubic_WTAR_1.RDS') # cache to disk
  
  # for each higher-class model, run with 5000 random starts based on the initial
  # one-class model, then run the selected one up to 1000 times to (hopeful) convergence:
  
  for (class_num in 2:max_classes_cubic) {
    
    print(class_num)
    
    # need to explicitly pass some variables to the namespace of each process, or the 
    # gridsearch and hlme functions below will trip up by not "knowing" some of their
    # parameters:
    parallel::clusterExport(cl, c('class_num', 'cubic_models'))
    
    cubic_models[[class_num]] <-
      lcmm::gridsearch(rep = 5000, maxiter = 100, minit = cubic_models[[1]], cl = cl,
                       hlme(WTAR ~ poly(age_std, degree = 3, raw = TRUE), 
                            random = ~1 + poly(age_std, degree = 3, raw = TRUE), 
                            ng = class_num, nwg = TRUE, maxiter = 1000,
                            mixture = ~ poly(age_std, degree = 3, raw = TRUE),
                            subject = 'subject_id_num', data = dat))
    
    saveRDS(cubic_models[[class_num]], paste0('models/cubic_WTAR_', class_num, '.RDS'))
  }
  
  parallel::stopCluster(cl)
  
} else { # use previously-computed cubic models:
  
  for (class_num in 1:max_classes_cubic) {
    cubic_models[[class_num]] = readRDS(paste0('models/cubic_WTAR_', class_num, '.RDS'))
  }
}

cubic_WTAR_model_table = 
  summarytable(cubic_models[[1]], cubic_models[[2]], cubic_models[[3]], cubic_models[[4]], cubic_models[[5]],
               which = c('G', 'loglik', 'npm', 'BIC', 'SABIC', 
                         'entropy', '%class')) %>% 
  as_tibble()

# select model, on the basis of one that converged and had the lowest BIC:
chosen_cubic_classes = 1
chosen_cubic_model   = cubic_models[[chosen_cubic_classes]]

# create a vector of ages to predict against, centred on the mean across all
# sessions, and in decades rather than years to limit polynomial instabilities):
mean_age = mean(dat$age) 
new_data_cubic = 
  data.frame(age = seq(from = 43, to = 89, by = 0.5)) %>% 
  mutate(age_std = (age - mean_age)/10)

# create a dataframe that contains predictions for all candidate models
# (will be used in the supplementary material).
predictions = list()

for (i in 1:max_classes_cubic) {
  prediction = lcmm::predictY(cubic_models[[i]], newdata = new_data_cubic, 
                              var.time = 'age_std', draws = TRUE)
  predictions[[i]] = 
    as.data.frame(prediction$pred) %>% # extract just the predicted values
    cbind(new_data_cubic) # and add in the corresponding age values
  predictions[[i]]$ng = i  # and label with the number of classes
}

# the first one needs to be modified so that it can act as the template to 
# row bind to the others:
predictions[[1]] = predictions[[1]] %>% # add a suffix to the variable names
  rename('Ypred_class1' = 'Ypred', 
         'lower.Ypred_class1' = 'lower.Ypred', 
         'upper.Ypred_class1' = 'upper.Ypred') %>% 
  select(ng, age, age_std, everything()) # set the order for the resulting dataframe

cubic_predictions = bind_rows(predictions[1:5]) %>% 
  # reshape to allow ggplotting:
  pivot_longer(cols = Ypred_class1:last_col(), 
               names_to = c('line', 'class'), names_sep = '_',
               values_to = 'predicted_WTAR') %>% 
  pivot_wider(names_from = line, values_from = predicted_WTAR) %>% 
  filter(!is.na(Ypred)) %>% 
  arrange(ng, class, age)

```

```{r wtar-modelling-linear, include=FALSE}

# prepare list to hold models with 1 through max_classes_linear classes:
linear_models = list()

if (RUN_NEW_LINEAR_MODELS) {
  
   # make use of parallel computation to speed up working through the large number of 
  # iterations to be used for each model:
  num_cores = parallel::detectCores()
  cl = parallel::makeCluster(num_cores)
  
  # currently have to coerce data to a dataframe (done above), as tibbles lead to 
  # a bug with the subject id column not being accepted by lcmm as numeric.
  
  # use the 1-class model to set initial start values:
  linear_models[[1]] <- lcmm::hlme(WTAR ~ age_std, 
                                 random = ~1 + age_std,
                                 subject = 'subject_id_num', ng = 1, 
                                 data = dat)
  saveRDS(linear_models[[1]], 'models/linear_WTAR_1.RDS') # cache to disk
  
  # for each higher-class model, run with 5000 random starts based on the initial
  # one-class model, then run the selected one up to 1000 times to (hopeful) convergence:
  
  for (class_num in 2:max_classes_linear) {
    
    print(class_num)
    
    # need to explicitly pass some variables to the namespace of each process, or the 
    # gridsearch and hlme functions below will trip up by not "knowing" some of their
    # parameters:
    parallel::clusterExport(cl, c('class_num', 'linear_models'))
    
    linear_models[[class_num]] <- 
      lcmm::gridsearch(rep = 5000, maxiter = 100, minit = linear_models[[1]], cl = cl,
                       hlme(WTAR ~ age_std, 
                            random = ~1 + age_std, 
                            ng = class_num, nwg = TRUE, 
                            mixture = ~ age_std, maxiter = 1000,
                            subject = 'subject_id_num', data = dat))
    
    saveRDS(linear_models[[class_num]], paste0('models/linear_WTAR_', class_num, '.RDS'))
  }
  
  parallel::stopCluster(cl)
  
} else { # use previously-computed linear models:
  
  for (class_num in 1:max_classes_linear) {
    linear_models[[class_num]] = readRDS(paste0('models/linear_WTAR_', class_num, '.RDS'))
  }
  
}

linear_WTAR_model_table = 
  summarytable(linear_models[[1]], linear_models[[2]], linear_models[[3]], linear_models[[4]], linear_models[[5]],
               which = c('G', 'loglik', 'npm', 'BIC', 'SABIC', 
                         'entropy', '%class')) %>% 
  as_tibble()

# select model, on the basis of one that converged and had the lowest BIC:
chosen_linear_classes = 2
chosen_linear_model   = linear_models[[chosen_linear_classes]]
coeffs = coef(chosen_linear_model)

# create a vector of ages to predict against, centred on the mean across all
# sessions, and in decades rather than years to be consistent with the cubic 
# modelling where we need to limit instabilities):
mean_age = mean(dat$age) 
new_data_linear = 
  data.frame(age = seq(from = 43, to = 89, by = 0.5)) %>% 
  mutate(age_std = (age - mean_age)/10)

# create a dataframe that contains predictions for all candidate models
predictions = list()

for (i in 1:max_classes_linear) {
  prediction = lcmm::predictY(linear_models[[i]], newdata = new_data_linear, 
                              var.time = 'age_std', draws = TRUE)
  predictions[[i]] = 
    as.data.frame(prediction$pred) %>% # extract just the predicted values
    cbind(new_data_linear) # and add in the corresponding age values
  predictions[[i]]$ng = i  # and label with the number of classes
}

# the first one needs to be modified so that it can act as the template to 
# row bind to the others:
predictions[[1]] = predictions[[1]] %>% # add a suffix to the variable names
  rename('Ypred_class1' = 'Ypred', 
         'lower.Ypred_class1' = 'lower.Ypred', 
         'upper.Ypred_class1' = 'upper.Ypred') %>% 
  select(ng, age, age_std, everything()) # set the order for the resulting dataframe

linear_predictions = bind_rows(predictions[1:5]) %>% 
  # reshape to allow ggplotting:
  pivot_longer(cols = Ypred_class1:last_col(), 
               names_to = c('line', 'class'), names_sep = '_',
               values_to = 'predicted_WTAR') %>% 
  pivot_wider(names_from = line, values_from = predicted_WTAR) %>% 
  filter(!is.na(Ypred)) %>% 
  arrange(ng, class, age)
  
chosen_linear_predictions = linear_predictions %>% 
  filter(ng == chosen_linear_classes) %>% 
  mutate(class = 
           factor(class, 
                  levels = c('class2', 'class1'),
                  labels = c('High performers', 'Typical'))) %>% 
  rename(class_for_lines = class)

# link subjects to their assigned classes:
dat_with_classes = dat %>% 
  left_join(chosen_linear_model$pprob, by = 'subject_id_num') %>% 
   mutate(class = 
           factor(class, 
                  levels = c('2', '1'),
                  labels = c('High performers', 'Typical'))) %>% 
  rowwise() %>% 
  mutate(class_probability = max(c(prob1, prob2)))

# get a dataframe with just one row per subject
individuals = dat_with_classes %>% 
  group_by(subject_id_num) %>% arrange(age) %>% 
  slice_tail()

class_proportions = individuals %>% 
  group_by(class) %>% 
  tally() %>%
  mutate(proportion = scales::percent_format(accuracy = 1)(n/sum(n)))

class_proportions_by_group = individuals %>% 
  group_by(group, class) %>% 
  tally() %>% group_by(group) %>% 
  mutate(proportion = scales::percent_format(accuracy = 1)(n/sum(n)))
```

The raw data showed that WTAR scores were relatively constant over time (see Figure \@ref(fig:figure-1)A), despite the substantial declines that could occur in overall cognitive function (Figure \@ref(fig:figure-1)B). Initially, however, we modeled WTAR scores as a polynomial (cubic) function of age, to allow for the depiction of any sub-clusters exhibiting curvilinear changes. The optimal cubic model showed a relatively flat trajectory, and we therefore shifted to modelling WTAR as a linear function of age, fitting candidate models ranging from one to five latent trajectory classes. We selected the two-class model on the basis of it having the lowest BIC value. Full details on the modelling process are provided in Supplementary Material.

We labelled the two resulting trajectory classes 'Typical' and 'High performers'. Individuals were assigned to the class for which they had the highest posterior classification probability. The mean assigned probability was `r round(mean(individuals$class_probability), digits = 2)` (`r round(sd(individuals$class_probability), digits = 2)`), with a value of 0.7 being regarded as acceptable model performance.[@lennon_framework_2018] The Typical trajectory captured `r class_proportions$proportion[class_proportions$class == 'Typical']` of all participants (`r class_proportions_by_group$proportion[class_proportions_by_group$class == 'Typical' & class_proportions_by_group$group == 'PD']` of the PD and `r class_proportions_by_group$proportion[class_proportions_by_group$class == 'Typical' & class_proportions_by_group$group == 'Control']` of Control participants). The 'High performers' trajectory (capturing the remaining `r class_proportions$proportion[class_proportions$class == 'High performers']` of all participants) had an intercept of `r sprintf('%.1f', coeffs[names(coeffs) == 'intercept class2'])`, representing the estimated WTAR of a person at the mean age of assessment (`r sprintf('%.1f', mean_age)` years). The slope of this trajectory indicated a decline of `r sprintf('%.1f', coeffs[names(coeffs) == 'age_std class2'])` points per decade (effectively flat). ***[TODO: Reza/Daniel - not sure how to get uncertainty around these estimates]*** The Typical trajectory, by contrast had an intercept of `r sprintf('%.1f', coeffs[names(coeffs) == 'intercept class1'][2])`, ***[TODO: Reza/Daniel - not sure why two coefficients with this name are returned, with one having a value that does not seem related to the actual one ]*** gently declining at a rate of `r sprintf('%.1f', coeffs[names(coeffs) == 'age_std class1'])` points per decade. ***[TODO: So far we haven't separated out the PD and Control groups with respect to latent class membership, as there doesn't seem to be a strong distinction. I guess we could formally test that though?]***

What other descriptive results might be useful (e.g. mean within-subject standard deviation, or range of WTAR scores? Not great for those with only two scores, though)? 

(ref:fig-1-caption) ***(A.)*** Longitudinal WTAR score trajectories for all individuals, divided into Controls, Parkinson's participants who remained dementia-free, and those who developed dementia. Also shown are the two predicted latent class trajectories (blue ribbon = _High performers_, brown ribbon = _Typical_). ***(B.)***  Global cognitive z-scores for the Parkinson's participants in the lower panel of (A) (those who developed dementia). Overall cognitive performance declined dramatically, in contrast to their relatively stable WTARs scores. This was regardless of their latent class (blue and brown lines). In each panel, current cognitive status is shown as cognitively normal (green circles), mild cognitive impairment (orange triangles), or dementia (red squares). Upon reaching dementia, the WTAR was not assessed again.

```{r figure-1, fig.align='center', fig.cap='(ref:fig-1-caption)', fig.height=fig_1_height/2.54, fig.width=fig_1_width/2.54, warning=FALSE}

# upper panel, of WTAR scores by age:
figure_1_upper = dat_with_classes %>% 
  ggplot(aes(x = age)) +
  facet_grid(panel_label ~ .) +
  scale_colour_manual(values = c('blue', 'brown'), name = 'Class', guide = 'none') + 
  scale_fill_manual(values = c('blue', 'brown'), name = 'Class', guide = 'none') + 
  geom_ribbon(dat = chosen_linear_predictions,
              aes(ymin = lower.Ypred, ymax = upper.Ypred, fill = class_for_lines),
              colour = NA, alpha = 0.2) +
  geom_line(dat = chosen_linear_predictions,
            aes(y = Ypred, colour = class_for_lines), 
            size = 0.25, linetype = 'dashed') +
  geom_line(aes(y = WTAR, colour = class, group = subject_id_num), 
            alpha = 1.0, size = 0.1) +
  new_scale_color() + new_scale_fill() +
  scale_colour_manual(values = cog_colours, name = 'Cognitive status') + 
  scale_fill_manual(values = cog_colours, name = 'Cognitive status') +
  # setting stroke = 0.1 gives nice sharp shapes:
  scale_shape_manual(values = c(21, 25, 22), name = 'Cognitive status') +
  geom_point(aes(y = WTAR, fill = cognitive_status,
                 #colour = cognitive_status, # minimal border stroke
                 shape = cognitive_status), colour = 'white', size = 1.0, stroke = 0.1) +

  scale_x_continuous(limits = c(42, 89.9), expand = c(0,0),
                     labels = scales::label_number(suffix = ' years')) +
  scale_y_continuous(limits = c(80, 130)) +
  labs(title = 'A. Longitudinal WTAR scores by group',
       subtitle = 'Showing raw scores and the two predicted latent class trajectories',
       x = NULL, y = NULL) +
  theme_bw() +
  theme(plot.title = element_text(face = 'bold', size = 9),
        plot.subtitle = element_text(size = 8),
        axis.text = element_text(size = 7, colour = 'black'),
        axis.ticks.y = element_line(colour = '#E8E8E8', size = 0.25),
        axis.ticks.x = element_blank(),
        panel.grid.major.y = element_line(colour = '#E8E8E8', size = 0.25),
        panel.grid.major.x = element_line(colour = '#C0C0C0', size = 0.5, 
                                          linetype = 'dotted'),
        panel.grid.minor = element_blank(),
        strip.text = element_text(face = 'plain', colour = 'black', size = 8),
        strip.background = element_rect(colour = '#C0C0C0', fill = '#C0C0C0'),
        panel.border = element_rect(colour = '#C0C0C0', size = 0.5),
        legend.pos = 'none', #c(0.09, 0.095),
        legend.margin = margin(c(1, 1, 1, 1), unit = 'mm'),
        legend.spacing.y = unit(1, 'mm'), # spacing between title & items
        legend.key.size = unit(2.5, 'mm'), # spacing between items
        legend.title = element_text(face = 'bold', size = 6),
        legend.text = element_text(size = 7))

# lower panel, of z-score trajectories of dementia-converters only:
figure_1_lower = dat_with_classes %>% 
  filter(panel_label == 'PD dementia') %>% 
  ggplot(aes(x = age, y = global_z)) +
  facet_grid(panel_label ~ .) +
  geom_line(aes(group = subject_id_num, colour = class), 
            alpha = 0.6, size = 0.25, show.legend = FALSE) +
  # setting stroke = 0.1 gives nice sharp shapes:
  geom_point(aes(fill = cognitive_status,
                 #colour = cognitive_status, # minimal border stroke
                 shape = cognitive_status), colour = 'white', size = 1.0, stroke = 0.1) +
  scale_colour_manual(values = c('blue', 'brown'), name = 'Class', guide = 'none') +
  scale_fill_manual(values = cog_colours, name = 'Cognitive status') +
  scale_shape_manual(values = c(21, 25, 22), name = 'Cognitive status') +
  scale_x_continuous(limits = c(42, 89.9), expand = c(0,0),
                     labels = scales::label_number(suffix = ' years')) +
  labs(title = 'B. Global cognitive z-scores',
       subtitle = 'Of those PD participants who developed dementia',
       x = NULL, y = NULL) + 
  theme_bw() +
  theme(plot.title = element_text(face = 'bold', size = 9),
        plot.subtitle = element_text(size = 8),
        axis.ticks = element_line(colour = '#E8E8E8', size = 0.25),
        axis.text = element_text(size = 7, colour = 'black'),
        panel.grid.major.y = element_line(colour = '#E8E8E8', size = 0.25),
        panel.grid.major.x = element_line(colour = '#C0C0C0', size = 0.5, 
                                          linetype = 'dotted'),
        panel.grid.minor = element_blank(),
        strip.text = element_text(face = 'plain', colour = 'black', size = 8),
        strip.background = element_rect(colour = '#C0C0C0', fill = '#C0C0C0'),
        panel.border = element_rect(colour = '#C0C0C0', size = 0.5),
        legend.position = c(0.085, 0.46), # 0.64 puts it in the top panel
        legend.margin = margin(c(1, 1, 1, 1), unit = 'mm'),
        legend.spacing.y = unit(1,'mm'), # spacing between title & items
        legend.key.size = unit(3.0,'mm'), # spacing between items
        legend.title = element_text(face = 'bold', size = 7),
        legend.text = element_text(size = 7))

figure_1 = cowplot::plot_grid(figure_1_upper, figure_1_lower, nrow = 2, axis = 'l',
                              align = 'v', rel_heights = c(1.0, 0.43))

figure_1

ggsave('images/wtar-figure-1.pdf', width = fig_1_width, height = fig_1_height,
       units = 'cm')
```

# Discussion

The raw data showed that WTAR scores are relatively stable over time in both controls and people with Parkinson's, despite many of the latter participants developing dementia over the course of the study (see Table \@ref(tab:table-1)). Nonetheless, latent class trajectory analysis revealed that people fell into one of two longitudinal clusters (Figure \@ref(fig:figure-1)). Those with very high initial WTAR scores remained at near-ceiling performance levels, even once they had developed dementia. The remaining `r class_proportions$proportion[class_proportions$class == 'Typical']` of participants had a wider range of initial scores, but were again relatively stable, with a mean estimated decline of only `r sprintf('%.1f', coeffs[names(coeffs) == 'age_std class1'])` points per decade.

Relevance to concept of cognitive reserve. This can lead to circular reasoning if the premorbid measure is not reliable. e.g. If a person with PD-MCI has a low measure of premorbid function, then this supports the concept of a strong cognitive reserve being protective against subsequent decline. But if the disease process reduces performance on that measure, then the inference is no longer valid. The findings shown here help bolster the use of WTAR as a valid measure of cognitive reserve in Parkinson's.

The WTAR is outdated inasmuch as it was originally devised to estimate WAIS-III scores. Third party predictions for the current WAIS-IV have been published,[@bright2020_ComparisonMethodsEstimating] although the WAIS-V is under development.

The WTAR (and NART) are also limited in that they are inherently tied to peculiarities of English. Many other languages have no equivalent irregularities in their mappings of graphemes to phonemes. In subsequent revisions of the PD-MCI criteria, if premorbid measures continue to be advocated, more attention should be given to alternative techniques[@franzen1997_MethodsEstimatingPremorbid] that could be valid in a wider international context.

The PD-MCI guidelines do not formalise how the results of these tests would be used in practice to demonstrate decline from a premorbid level of function.[@marras2014_ToolsTradeState]. We are aware of only one study[@marras2013_MeasuringMildCognitive] ***[TODO - Kyla - is this true?]*** that has compared the norms-based vs premorbid approaches to establishing cognitive impairment. They converted the WTAR-estimated full-scale IQ to a z-score and used that as the reference against which to test each individual neuropsychological test z-score, with a test that was lower by more than 1.5 SD deemed impaired. Of a sample of 139 non-demented people with Parkinson's, the WTAR method classified many more of them as having PD-MCI (79%) than the usual norms-based Level II classification method (33%). Marras _et al._ interpreted this as evidence that most people with Parkinson's have undergone at least some decline relative to their premorbid function. Conversely it might be that the WTAR over-estimates that level of function - for example, in our sample the distribution of estimated IQ values _(mean and SD per group shown in Table \@ref(tab:table-1))_ were well above the supposed population mean of 100 ***(TODO: SD 15? Kyla to comment on expected range.)***. 


# References


