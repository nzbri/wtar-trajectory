---
title: The Wechsler Test of Adult Reading is a stable measure of premorbid cognitive
  function in Parkinson's
author:
- name: Kyla-Louise Horne, PhD
  affiliation: '1'
- name: Reza Shoorangiz, PhD
  affiliation: '1,2,3'
- name: Daniel J. Myall, PhD
  affiliation: '1'
- name: Tim J. Anderson, MD, FRACP
  affiliation: '1,2,4'
- name: John C. Dalrymple-Alford, PhD
  affiliation: '1,2,5'
- name: Michael R. MacAskill, PhD
  affiliation: '1,2'
  corresponding: yes
  address: 66 Stewart St, Christchurch 8011, New Zealand
  email: michael.macaskill@nzbri.org
shorttitle: Parkinson's premorbid function
output:
  papaja::apa6_pdf:
  papaja::apa6_word:
link-citations: yes
csl: format/sage-vancouver.csl
bibliography: format/wtar-references.bib
appendix: 2021-wtar-supplementary.Rmd
linenumbers: yes
mask: no
draft: no
documentclass: apa6
classoption: man
affiliation:
- id: '1'
  institution: New Zealand Brain Research Institute, 66 Stewart St, Christchurch,
    New Zealand
- id: '2'
  institution: Department of Medicine, University of Otago, Christchurch; Christchurch,
    New Zealand
- id: '3'
  institution: Department of Electrical and Computer Engineering, University of Canterbury,
    Christchurch, New Zealand
- id: '4'
  institution: Department of Neurology, Christchurch Hospital, Christchurch, New Zealand
- id: '5'
  institution: School of Psychology, Speech, and Hearing, University of Canterbury,
    Christchurch, New Zealand
abstract: Background. A measure of premorbid cognitive function 
  such as the WechslerTest of Adult Reading (WTAR) is recommended to be 
  considered when determining the current cognitive status of people with 
  Parkinson's disease. WTAR scores are known to decline in Alzheimer's disease, 
  however, and it has not been formally demonstrated that they remain stable in 
  spite of the cognitive deterioration that occurs in Parkinson's. 
  Objectives. Assess long-term trajectories of WTAR scores in people with 
  Parkinson's as a function of age. Methods. From 253 Parkinson's and 57 
  Control participants who had completed at least two WTARs, we analysed scores
  using latent class trajectory analysis. Results. WTAR was stable in this 
  sample. Conclusion. The WTAR is a stable measure of premorbid function 
  despite the substantial cognitive decline exhibited by many of the 
  participants.
keywords: Parkinson disease, cognitive impairment, dementia, neuropsychology
wordcount: 'Abstract: up to 150, main body: up to 1700'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE)

options(knitr.kable.NA = '')
```

```{r define-variables}
################################################################################
### 1. To save time taken by re-importing live data online everytime this  
###    document is generated, set the following variable to be FALSE. This will 
###    instead import static values from a locally-cached file.
### 2. Eventually, an anonymised cached version of the dataset(s) will be 
###    distributed publicly with these files, so that external (non-NZBRI) users
###    can also generate and alter the document, without needing the live data 
###    import functions provided by the in-house `chchpd` package.
### 3. We also can choose not to re-compute the latent class models on each run,
###    and instead use cached model objects to save re-computing them each time.
################################################################################
IMPORT_LIVE_DATA = FALSE

RUN_NEW_CUBIC_MODELS  = FALSE
RUN_NEW_LINEAR_MODELS = FALSE

################################################################################

# define the maximum number of classes to run models to:
max_classes_cubic = 5
max_classes_linear = 5

# define colour scheme values for normal, MCI, and dementia:
cog_colours <- c('#339900', '#FF9326', '#D92121')

# colour schemes for two categories (e.g. male/female):
orange_blue = c('#D55E00', '#0072B2')
blue_orange = c('#599BC2', '#E08F6B')
blue_orange_sat = c('#0072B2', '#D55E00')

fig_1_width = 17.5;   fig_1_height = 16.5

```

```{r import-packages}
# An NZBRI-only in-house package for importing the latest live data:
if (IMPORT_LIVE_DATA) {
  library(chchpd) # initial install via devtools::install_github('nzbri/chchpd')
}

# tidyverse libraries:
library(readr)       # to read/write locally cached .csv data files
library(dplyr)       # for data manipulation
library(tidyr)       # for fill & pivot_
library(lubridate)   # for date intervals
library(magrittr)    # for the %<>% operator
library(ggplot2)     # for visualisation
library(scales)      # improved labelling in ggplot
library(ggnewscale)  # allow multiple colour scales in ggplot
library(directlabels)# to label lines on plots
library(cowplot)     # combine multiple separate plots in one figure
library(lcmm)        # latent class models
library(parallel)    # for parallel computation
library(huxtable)    # tables that work in Word output
library(knitr)       # for kable pretty tables
library(kableExtra)  # extra kable options
library(papaja)      # for apa_table

```

```{r import-data}
# evaluated only if the chchpd package has been imported, to 
# access live data sources.
 
if (IMPORT_LIVE_DATA) { # put this here for when not knitting

participants = chchpd::import_participants(anon_id = FALSE) %>% 
    rename(group = participant_group)

sessions = chchpd::import_sessions() %>% 
  # the PDD follow-up sessions were mostly not coded as part of the 
  # Progression study, so gather sessions from both:
  filter(study %in% c('Follow-up', 'PDD Followup')) %>% 
  # but some sessions *were* entered in both studies, so remove any duplicates:
  group_by(session_id) %>% 
  filter(row_number() == 1) %>% 
  # this person's session seems to have a fictitious WTAR score (none should
  # have been gathered on that session, no original can be found, 
  # and the value changes so markedly from the two previous ones that it 
  # results in a separate class just to fit this one person). Can 
  # drop this filter step once the value is removed from the database:
  filter(session_id != '310PDS_2020-03-04')

np = chchpd::import_neuropsyc()
updrs = chchpd::import_motor_scores()

}
```

```{r collate-dataset}
if (IMPORT_LIVE_DATA) {

dat = right_join(participants, sessions, by = 'subject_id') %>%
  left_join(np, by = 'session_id') %>% 
  left_join(updrs, by = 'session_id')

dat = dat %>%
  filter(np_group %in% c('Control', 'PD'), # exclude atypical cases
         !is.na(cognitive_status),         # remove not-yet classified sessions
         !is.na(WTAR)) %>%                
  mutate(group = factor(group, levels = c('Control', 'PD'))) %>% 
  mutate(cognitive_status = factor(cognitive_status, 
                                   levels = c('N', 'MCI', 'D'),
                                   labels = c('Normal', 'MCI', 'Dementia'))) %>% 
  group_by(subject_id) %>% 
  arrange(years_from_baseline) %>%
  mutate(assessment_num = row_number()) %>% 
  mutate(n_sessions = max(assessment_num)) %>% 
  filter(n_sessions > 1) %>% # exclude cases without follow-up
  mutate(ever_demented = 'Dementia' %in% cognitive_status) %>% 
  # to make line colours match the destination point rather than the origin 
	# point, need to use a diagnosis variable that leads the current diagnosis
	# for each person by one step:
	mutate(cognitive_status_lead = lead(cognitive_status)) %>% 
	# this makes the last value for each person NA, which can cause issues. 
	# fill() replaces them with the latest previous diagnosis:
  fill(cognitive_status_lead) %>% 
  mutate(sampling_interval = 
           years_from_baseline - lag(years_from_baseline)) %>% 
  # should be much the same but here to be explicit:
  mutate(wtar_interval = 
           interval(start = lag(session_date), end = session_date)/years(1)) %>% 
  ungroup()


# lcmm insists on access to a numeric subject variable:
dat = dat %>% 
  mutate(subject_id = factor(subject_id)) %>% 
  mutate(subject_id_num = as.integer(subject_id))

# for lcmm we standardise the age to avoid problems with polynomial effects, 
# as per Proust-Lima et al. (2017). Note that we are using the grand mean age at 
# assessment, rather than averaging across some landmark age for each subject. 
# We use the same standardisation for the linear models, so we can compare them.
dat$age_std = (dat$age - mean(dat$age))/10

dat = dat %>% 
  arrange(subject_id_num, age) %>% 
  select(subject_id_num, group,	sex, symptom_onset_age,	diagnosis_age,
         education, age, age_std, wtar_interval, group, cognitive_status, 
         cognitive_status_lead, ever_demented, WTAR, MoCA, global_z, 
         attention_domain, executive_domain, visuo_domain,
         learning_memory_domain,	language_domain, H_Y,	Part_III)
         

# store a cached version of the dataset for optional access on subsequent runs 
# of generating this document:
dat %>% write_csv(file = 'data/dat_wtar.csv')

}

# Regardless of whether IMPORT_LIVE_DATA has been set to TRUE, we import from 
# a cached, static dataset rather to ensure consistency:
dat = read_csv(file = 'data/dat_wtar.csv') %>% 
  mutate(cognitive_status = factor(cognitive_status, 
                                   levels = c('Normal', 'MCI', 'Dementia')),
         cognitive_status_lead = factor(cognitive_status_lead, 
                                        levels = c('Normal', 'MCI', 'Dementia'))) %>% 
  # divide subjects into three panels in the figure:
  mutate(panel_label = 
           case_when(group == 'Control'     ~ 'Control',
                     ever_demented == FALSE ~ 'PD non-dementia',
                     TRUE                   ~ 'PD dementia'),
         panel_label = 
           factor(panel_label, 
                  levels = c('Control', 'PD non-dementia', 'PD dementia'))) %>% 
  # do this to avoid an issue with lcmm not correctly detecting numeric
  # column types in a tibble:
  as.data.frame()

```

# Introduction

In 2012, the International Parkinson and Movement Disorder Society published its Taskforce guidelines for the diagnosis of mild cognitive impairment in Parkinson's disease (PD-MCI).[@litvan2012_DiagnosticCriteriaMild] When the diagnosis is based on specific (rather than global) neuropsychological tests, significant impairment may be determined in three ways: (i) performance below appropriate norms, or (ii) decline on serial testing, or (iii) decline from estimated premorbid levels. The latter two approaches could be advantageous in resolving the ambiguity that poor current cognitive function might reflect long-standing low cognitive ability, rather than a recent disease-related deterioration. In practice, however, one seldom has reference to prior formal serial testing, and so a valid method of estimating premorbid function is appealing. The Wechsler Test of Adult Reading (WTAR) was proposed in the guidelines as one of two recommended tests to estimate premorbid functioning (along with the National Adult Reading Test, NART). Both tests are based on being able to recognise and pronounce irregularly-spelled English words. ***[TODO: give some examples]*** This ability has been shown to be preserved in the face of both normal ageing and a number of brain insults[@strauss2006_CompendiumNeuropsychologicalTests] 

When the test was initially normed, it was tested in Parkinson's as well as a number of other neurological disorders, such as Huntington's, schizophrenia, and traumatic brain injury. Only in Alzheimer's disease were the scores significantly lower than in matched controls.[@strauss2006_CompendiumNeuropsychologicalTests] ***[TODO - read and insert reference to the Wechsler manual]***. Those results were published in 2001, well before the current guidelines on diagnosing PD-MCI[@litvan2012_DiagnosticCriteriaMild] and Parkinson's dementia[@dubois2007_DiagnosticProceduresParkinson] were promulgated. It is therefore unclear to what extent those original findings are valid in the face of the significant cognitive deterioration that can occur in Parkinson's.

We therefore firstly sought to examine WTAR scores in a cognitively well-characterised sample, spanning the range from normal function through mild cognitive impairment to dementia. Secondly, we restricted the sample to participants who had completed a minimum of two WTARs, so that the stability of the measure within individuals over time could be examined.    

# Methods

```{r descriptives}
group_n = dat %>% 
  group_by(subject_id_num) %>% 
  mutate(session_num = row_number(),
         n_sessions = max(session_num)) %>% 
  slice_head() %>% # one row per subject
  group_by(group) %>% 
  summarise(n = n(), 
            min_sessions = min(n_sessions),
            mean_sessions = mean(n_sessions),
            sd_sessions = sd(n_sessions),
            max_sessions = max(n_sessions))

wtar_n = dat %>% 
  group_by(subject_id_num) %>% 
  mutate(session_num = row_number(),
         n_sessions = max(session_num)) %>% 
  slice_head() %>% # one row per subject
  ungroup() %>% 
  summarise(n = n(), 
            min_sessions = min(n_sessions),
            mean_sessions = mean(n_sessions),
            sd_sessions = sd(n_sessions),
            max_sessions = max(n_sessions),
            total_sessions = sum(n_sessions))

```

The New Zealand Parkinson's Progression Programme is a longitudinal study of a convenience prevalence sample of idiopathic Parkinson's, largely recruited from the specialist Movement Disorders Clinic at the New Zealand Brain Research Institute. The study commenced in 2007, with recruitment ongoing, and hence covers patients ranging from the recently-diagnosed to those with advanced disease. Inclusion and exclusion criteria have been described previously [@wood2016_DifferentPDMCICriteria]. For this analysis, we selected data only from the `r group_n$n[group_n$group == 'PD']` Parkinson's and `r group_n$n[group_n$group == 'Control']` Control participants who had completed at least two WTARs (range 2 - `r wtar_n$max_sessions`, mean = `r wtar_n$mean_sessions`, total number of measures = `r wtar_n$total_sessions`). The period between successive WTAR assessments was multi-modal, mostly clustering around intervals of one and two years, due to varying follow-up periods over the course of the study. Both patients and controls were classified as having normal cognition, mild cognitive impairment, or dementia on the basis of a comprehensive neuropsychological battery[@dalrymple-alford2011_CharacterizingMildCognitive; @wood2016_DifferentPDMCICriteria], administered in accordance with MDS guidelines[@dubois2007_DiagnosticProceduresParkinson; @litvan2012_DiagnosticCriteriaMild]. Although the WTAR was assessed during each session, we did not actually use it in the diagnostic classification process: this was done on the basis of test scores falling below 1.5 standard deviations of norms,[@dalrymple-alford2011_CharacterizingMildCognitive; @wood2016_DifferentPDMCICriteria] rather than being compared to an estimated pre-morbid level. Characteristics of the sample are shown in Table \@ref(tab:table-1). All participants were speakers of New Zealand English, and were assessed against the ***TODO:*** UK? norms of the WTAR, corrected for age, sex, and years of education. ***{TODO: Kyla to confirm UK norms, and any other relevant details.]***

## Latent class trajectory modelling

We fitted latent class trajectory models using the $hlme$ function from the $lcmm$ package [@proust-lima_estimation_2017] (version `r packageVersion('lcmm')`), running in the R statistical environment [@R-Core-Team_R_2021] (version `r R.version$major`.`r R.version$minor`). The dependent variable was WTAR estimated IQ, initially modelled within each subject as a polynomial (cubic) function of age, to allow for non-linear trajectories. The resulting trajectories were close to straight lines and thus we simplified the models to be a linear function of age. The models were unaware of any other variables (such as categorical MCI or dementia diagnoses). We fitted five separate models, with the specified number of latent classes increasing from 1 to 5. The model with just one latent class was used to provide starting values for the subsequent models with multiple classes. For each of the multi-class models, an estimation function was run 100 times using an automatic grid search to estimate the parameters while avoiding local minima ***?or maxima? Check with Daniel & Reza on the phrasing of this process.***. Parameters corresponding to the best log-likelihood were used as initial values for the final estimation of the parameters [@proust-lima_estimation_2017]. Selection of the optimal model was on the basis of selecting the one with the lowest BIC value.

```{r table-1}
table_df = dat %>% 
  group_by(subject_id_num) %>% 
  arrange(age) %>% 
  slice_tail() %>% # last observation per subject
  group_by(group) %>% 
  summarise(n = n(),
            Male   = scales::percent_format(accuracy = 0.1)(sum(sex == 'Male')/n),
            Age = paste0(sprintf('%.1f', mean(age)), ' (', sprintf('%.1f',sd(age)), ')'),
            Education = paste0(sprintf('%.1f', mean(education)), ' (', sprintf('%.1f', sd(education)), ')'),
            WTAR = paste0(sprintf('%.1f', mean(WTAR)), ' (', sprintf('%.1f', sd(WTAR)), ')'),
            Normal = scales::percent_format(accuracy = 0.1)(sum(cognitive_status == 'Normal')/n),
            MCI    = scales::percent_format(accuracy = 0.1)(sum(cognitive_status == 'MCI')/n),
            Dementia = scales::percent_format(accuracy = 0.1)(sum(cognitive_status == 'Dementia')/n)) %>% 
  mutate(n = as.character(n)) %>% 
  pivot_longer(n:Dementia) %>% 
  pivot_wider(names_from = 'group')

table_df %>% 
  mutate(name = case_when(name == 'Education' ~ 'Education (years)',
                          name == 'Normal'    ~ 'Normal cognition',
                          TRUE                ~ name)) %>% 
  rename(' '           = name,
         "Parkinson's" = PD) %>%
  apa_table(caption = "Demographics of the Parkinson's and Control groups, as at their latest assessment.", align = 'lrr') #%>% 
  # kable(caption = "Demographics of the Parkinson's and Control groups, as at their latest assessment.", align = 'lrr') %>% #, vline = '')#, booktabs = TRUE) %>%
  #kable_styling(position = 'center') %>%
  #row_spec(0, bold = TRUE)

```


## Reproducibility

The code and anonymised dataset extracts sufficient to reproduce the analyses and generate this manuscript (using the _papaja_[@aust2020papaja] R Markdown package) are publicly available at https://github.com/nzbri/wtar-trajectory.

- Assess our achievement against one of these guidelines for reporting latent trajectory studies, report in supplementary material: [@lennon_framework_2018; @van_de_schoot_grolts-checklist_2017]

# Results

```{r wtar-modelling-cubic, include=FALSE}

# prepare list to hold models with 1 through max_classes_cubic classes:
cubic_models = list()

if (RUN_NEW_CUBIC_MODELS) {

  # make use of parallel computation to speed up working through the large number of 
  # iterations to be used for each model:
  num_cores = parallel::detectCores()
  cl = parallel::makeCluster(num_cores)
  
  # currently have to coerce data to a dataframe (done above), as tibbles lead to 
  # a bug with the subject id column not being accepted by lcmm as numeric.
  
  # use the 1-class model to set initial start values:
  cubic_models[[1]] <- lcmm::hlme(WTAR ~ poly(age_std, degree = 3, raw = TRUE), 
                                  random = ~1 + poly(age_std, degree = 3, raw = TRUE),
                                  subject = 'subject_id_num', ng = 1, 
                                  data = dat)
  saveRDS(cubic_models[[1]], 'models/cubic_WTAR_1.RDS') # cache to disk
  
  # for each higher-class model, run with 5000 random starts based on the initial
  # one-class model, then run the selected one up to 1000 times to (hopeful) convergence:
  
  for (class_num in 2:max_classes_cubic) {
    
    print(class_num)
    
    # need to explicitly pass some variables to the namespace of each process, or the 
    # gridsearch and hlme functions below will trip up by not "knowing" some of their
    # parameters:
    parallel::clusterExport(cl, c('class_num', 'cubic_models'))
    
    cubic_models[[class_num]] <-
      lcmm::gridsearch(rep = 5000, maxiter = 100, minit = cubic_models[[1]], cl = cl,
                       hlme(WTAR ~ poly(age_std, degree = 3, raw = TRUE), 
                            random = ~1 + poly(age_std, degree = 3, raw = TRUE), 
                            ng = class_num, nwg = TRUE, maxiter = 1000,
                            mixture = ~ poly(age_std, degree = 3, raw = TRUE),
                            subject = 'subject_id_num', data = dat))
    
    saveRDS(cubic_models[[class_num]], paste0('models/cubic_WTAR_', class_num, '.RDS'))
  }
  
  parallel::stopCluster(cl)
  
} else { # use previously-computed cubic models:
  
  for (class_num in 1:max_classes_cubic) {
    cubic_models[[class_num]] = readRDS(paste0('models/cubic_WTAR_', class_num, '.RDS'))
  }
}

cubic_WTAR_model_table = 
  summarytable(cubic_models[[1]], cubic_models[[2]], cubic_models[[3]], cubic_models[[4]], cubic_models[[5]],
               which = c('G', 'loglik', 'npm', 'BIC', 'SABIC', 
                         'entropy', '%class')) %>% 
  as_tibble()

# select model, on the basis of one that converged and had the lowest BIC:
chosen_cubic_model = cubic_models[[1]]

# create some a vector of ages to predict against, but first:
# need to calculate this based on the real data (we choose to mean across all
# sessions rather than across one value per subject):
mean_age = mean(dat$age) 
new_data_cubic = 
  data.frame(age = seq(from = 47.5, to = 87.5, by = 0.5)) %>% 
  mutate(age_std = (age - mean_age)/10)

pred_cubic_WTAR = predictY(chosen_cubic_model, newdata = new_data_cubic, 
                       var.time = 'age_std', draws = TRUE)
pred_cubic_WTAR = cbind(new_data_cubic, pred_cubic_WTAR$pred) %>% 
   # reshape to allow ggplotting:
  pivot_longer(cols = Ypred:upper.Ypred, 
               names_to  = 'line',
               values_to = 'predicted_WTAR') %>% 
  pivot_wider(names_from = line, values_from = predicted_WTAR)

figure_cubic_3 = pred_cubic_WTAR %>% 
  ggplot(aes(x = age, y = Ypred)) +
  geom_ribbon(aes(ymin = lower.Ypred, ymax = upper.Ypred), 
              fill = 'brown', colour = NA, alpha = 0.3) +
  geom_line(colour = 'brown') +
  scale_x_continuous(minor_breaks = NULL,
                     labels = scales::label_number(suffix = ' yrs')) +
  scale_y_continuous(limits = c(80, 130)) +
  labs(title = 'A. Predicted WTAR scores',
       x = NULL, y = NULL) +
  theme_bw() + 
  theme(aspect.ratio = 1,
        plot.title = element_text(face = 'bold', size = 10),
        axis.ticks = element_line(colour = '#E8E8E8'),
        axis.text = element_text(size = 8),
        axis.title = element_text(size = 9),
        panel.border = element_rect(colour = '#E8E8E8', size = 1.0),
        strip.background = element_rect(fill = '#E8E8E8',
                                        colour = '#E8E8E8'),
        panel.spacing.x = unit(10, 'mm'),
        legend.position = 'none')

ggsave('images/cubic_predicted_class_trajectories.pdf', plot = figure_cubic_3,
       width = 10, height = 10, units = 'cm')

```

```{r wtar-modelling-linear, include=FALSE}

# prepare list to hold models with 1 through max_classes_linear classes:
linear_models = list()

if (RUN_NEW_LINEAR_MODELS) {
  
   # make use of parallel computation to speed up working through the large number of 
  # iterations to be used for each model:
  num_cores = parallel::detectCores()
  cl = parallel::makeCluster(num_cores)
  
  # currently have to coerce data to a dataframe (done above), as tibbles lead to 
  # a bug with the subject id column not being accepted by lcmm as numeric.
  
  # use the 1-class model to set initial start values:
  linear_models[[1]] <- lcmm::hlme(WTAR ~ age_std, 
                                 random = ~1 + age_std,
                                 subject = 'subject_id_num', ng = 1, 
                                 data = dat)
  saveRDS(linear_models[[1]], 'models/linear_WTAR_1.RDS') # cache to disk
  
  # for each higher-class model, run with 5000 random starts based on the initial
  # one-class model, then run the selected one up to 1000 times to (hopeful) convergence:
  
  for (class_num in 2:max_classes_linear) {
    
    print(class_num)
    
    # need to explicitly pass some variables to the namespace of each process, or the 
    # gridsearch and hlme functions below will trip up by not "knowing" some of their
    # parameters:
    parallel::clusterExport(cl, c('class_num', 'linear_models'))
    
    linear_models[[class_num]] <- 
      lcmm::gridsearch(rep = 5000, maxiter = 100, minit = linear_models[[1]], cl = cl,
                       hlme(WTAR ~ age_std, 
                            random = ~1 + age_std, 
                            ng = class_num, nwg = TRUE, 
                            mixture = ~ age_std, maxiter = 1000,
                            subject = 'subject_id_num', data = dat))
    
    saveRDS(linear_models[[class_num]], paste0('models/linear_WTAR_', class_num, '.RDS'))
  }
  
  parallel::stopCluster(cl)
  
} else { # use previously-computed linear models:
  
  for (class_num in 1:max_classes_linear) {
    linear_models[[class_num]] = readRDS(paste0('models/linear_WTAR_', class_num, '.RDS'))
  }
  
}

linear_WTAR_model_table = 
  summarytable(linear_models[[1]], linear_models[[2]], linear_models[[3]], linear_models[[4]], linear_models[[5]],
               which = c('G', 'loglik', 'npm', 'BIC', 'SABIC', 
                         'entropy', '%class')) %>% 
  as_tibble()

# select model, on the basis of one that converged and had the lowest BIC:
chosen_linear_model = linear_models[[2]]

# create some a vector of ages to predict against, but first:
# need to calculate this based on the real data (we choose to mean across all
# sessions rather than across one value per subject):
mean_age = mean(dat$age) 
new_data_linear = 
  data.frame(age = seq(from = 43, to = 89, by = 0.5)) %>% 
  mutate(age_std = (age - mean_age))

pred_linear_WTAR <- predictY(chosen_linear_model, newdata = new_data_linear, 
                       var.time = 'age_std', draws = TRUE)
pred_linear_WTAR = cbind(new_data_linear, pred_linear_WTAR$pred) %>% 
  # reshape to allow ggplotting:
  pivot_longer(cols = Ypred_class1:upper.Ypred_class2, 
               names_to = c('line', 'class'), names_sep = '_',
               values_to = 'predicted_WTAR') %>% 
  pivot_wider(names_from = line, values_from = predicted_WTAR) %>% 
  mutate(class = 
           factor(class, 
                  levels = c('class2', 'class1'),
                  labels = c('High and stable', 'Typical')))

# add group so it can be used for plotting:
pred_linear_WTAR_group = 
  rbind(pred_linear_WTAR, pred_linear_WTAR) %>% 
  mutate(group = rep(c('Control', 'PD'), each = nrow(pred_linear_WTAR))) %>% 
  select(group, everything())

# link subjects to their assigned classes:
dat_with_classes = dat %>% 
  left_join(chosen_linear_model$pprob, by = 'subject_id_num') %>% 
   mutate(class = 
           factor(class, 
                  levels = c('2', '1'),
                  labels = c('High and stable', 'Typical'))) %>% 
  rowwise() %>% 
  mutate(class_probability = max(c(prob1, prob2)))

# get a dataframe with just one row per subject
individuals = dat_with_classes %>% 
  group_by(subject_id_num) %>% arrange(age) %>% 
  slice_tail()

class_proportions = individuals %>% 
  group_by(group, class) %>% 
  tally() %>% group_by(group) %>% 
  mutate(proportion = scales::percent_format(accuracy = 0.1)(n/sum(n)))

class_proportions
  

```

- See Figure \@ref(fig:figure-1).
- Describe the model selection process.
- Need to describe the form of the single latent class. Currently using a cubic, which isn't great in terms of describing the parameters. Ideally would start with a cubic and then drop back to linear, but that gives odd results we need to discuss (e.g. a 2-class model with a lower BIC but the second class contains only one person).
- Individuals were assigned to the class for which they had the highest posterior probability of assignment. The mean assigned probability was `r round(mean(dat_with_classes$class_probability), digits = 2)` (`r round(sd(dat_with_classes$class_probability), digits = 2)`), with a value of 0.7 regarded as acceptable model performance.[@lennon_framework_2018] 
- What other descriptive results might be useful (e.g. mean within-subject standard deviation of WTAR scores? Not great for those with only two scores, though)? Maybe plot within subject SDs of global z vs WTAR (see supplementary material)? 

(ref:fig-1-caption) ***(A.)*** Longitudinal WTAR score trajectories for all individuals, divided into Controls, Parkinson's participants who remained dementia-free, and those who developed dementia. Also shown are the two predicted latent class trajectories (blue ribbon = _High and stable_, brown ribbon = _Typical_). ***(B.)***  Global cognitive z-scores for the Parkinson's participants in the lower panel of ***(A)*** (those who developed dementia). Overall cognitive performance declined dramatically, in contrast to their relatively stable WTARs scores. This was regardless of their latent class (blue and brown lines). In each panel, current cognitive status is shown as cognitively normal (green circles), mild cognitive impairment (orange triangles), or dementia (red squares). Upon reaching dementia, the WTAR was not assessed again.

```{r figure-1, fig.align='center', fig.cap='(ref:fig-1-caption)', fig.height=fig_1_height/2.54, fig.width=fig_1_width/2.54}

dat_plotting = dat_with_classes %>% 
  mutate(group = factor(group, levels = c('Control', 'PD')))
pred_linear_WTAR_group_plotting = pred_linear_WTAR_group %>% 
  rename(class_for_lines = class) %>% 
  mutate(group = factor(group, levels = c('Control', 'PD')))

# upper panel, of WTAR scores by age:
figure_1_upper = dat_plotting %>% 
  ggplot(aes(x = age)) +
  facet_grid(panel_label ~ .) +
  scale_colour_manual(values = c('blue', 'brown'), name = 'Class', guide = 'none') + 
  scale_fill_manual(values = c('blue', 'brown'), name = 'Class', guide = 'none') + 
  geom_ribbon(dat = pred_linear_WTAR_group_plotting,
              aes(ymin = lower.Ypred, ymax = upper.Ypred, fill = class_for_lines),
              colour = NA, alpha = 0.2) +
  geom_line(dat = pred_linear_WTAR_group_plotting,
            aes(y = Ypred, colour = class_for_lines), 
            size = 0.25, linetype = 'dashed') +
  geom_line(aes(y = WTAR, colour = class, group = subject_id_num), 
            alpha = 1.0, size = 0.1) +
  new_scale_color() + new_scale_fill() +
  scale_colour_manual(values = cog_colours, name = 'Cognitive status') + 
  scale_fill_manual(values = cog_colours, name = 'Cognitive status') +
  # setting stroke = 0.1 gives nice sharp shapes:
  scale_shape_manual(values = c(21, 25, 22), name = 'Cognitive status') +
  geom_point(aes(y = WTAR, fill = cognitive_status,
                 #colour = cognitive_status, # minimal border stroke
                 shape = cognitive_status), colour = 'white', size = 1.0, stroke = 0.1) +

  scale_x_continuous(limits = c(42, 89.9), expand = c(0,0),
                     labels = scales::label_number(suffix = ' years')) +
  scale_y_continuous(limits = c(80, 130)) +
  labs(title = 'A. Longitudinal WTAR scores by group',
       subtitle = 'Showing raw scores and the two predicted latent class trajectories',
       x = NULL, y = NULL) +
  theme_bw() +
  theme(plot.title = element_text(face = 'bold', size = 9),
        plot.subtitle = element_text(size = 8),
        axis.text = element_text(size = 7, colour = 'black'),
        axis.ticks.y = element_line(colour = '#E8E8E8', size = 0.25),
        axis.ticks.x = element_blank(),
        panel.grid.major.y = element_line(colour = '#E8E8E8', size = 0.25),
        panel.grid.major.x = element_line(colour = '#C0C0C0', size = 0.5, 
                                          linetype = 'dotted'),
        panel.grid.minor = element_blank(),
        strip.text = element_text(face = 'plain', colour = 'black', size = 8),
        strip.background = element_rect(colour = '#C0C0C0', fill = '#C0C0C0'),
        panel.border = element_rect(colour = '#C0C0C0', size = 0.5),
        legend.pos = 'none', #c(0.09, 0.095),
        legend.margin = margin(c(1, 1, 1, 1), unit = 'mm'),
        legend.spacing.y = unit(1, 'mm'), # spacing between title & items
        legend.key.size = unit(2.5, 'mm'), # spacing between items
        legend.title = element_text(face = 'bold', size = 6),
        legend.text = element_text(size = 7))

# lower panel, of z-score trajectories of dementia-converters only:
figure_1_lower = dat_with_classes %>% 
  filter(panel_label == 'PD dementia') %>% 
  ggplot(aes(x = age, y = global_z)) +
  facet_grid(panel_label ~ .) +
  geom_line(aes(group = subject_id_num, colour = class), 
            alpha = 0.6, size = 0.25, show.legend = FALSE) +
  # setting stroke = 0.1 gives nice sharp shapes:
  geom_point(aes(fill = cognitive_status,
                 #colour = cognitive_status, # minimal border stroke
                 shape = cognitive_status), colour = 'white', size = 1.0, stroke = 0.1) +
  scale_colour_manual(values = c('blue', 'brown'), name = 'Class', guide = 'none') +
  scale_fill_manual(values = cog_colours, name = 'Cognitive status') +
  scale_shape_manual(values = c(21, 25, 22), name = 'Cognitive status') +
  scale_x_continuous(limits = c(42, 89.9), expand = c(0,0),
                     labels = scales::label_number(suffix = ' years')) +
  labs(title = 'B. Global cognitive z-scores',
       subtitle = 'Of those PD participants who developed dementia',
       x = NULL, y = NULL) + 
  theme_bw() +
  theme(plot.title = element_text(face = 'bold', size = 9),
        plot.subtitle = element_text(size = 8),
        axis.ticks = element_line(colour = '#E8E8E8', size = 0.25),
        axis.text = element_text(size = 7, colour = 'black'),
        panel.grid.major.y = element_line(colour = '#E8E8E8', size = 0.25),
        panel.grid.major.x = element_line(colour = '#C0C0C0', size = 0.5, 
                                          linetype = 'dotted'),
        panel.grid.minor = element_blank(),
        strip.text = element_text(face = 'plain', colour = 'black', size = 8),
        strip.background = element_rect(colour = '#C0C0C0', fill = '#C0C0C0'),
        panel.border = element_rect(colour = '#C0C0C0', size = 0.5),
        legend.position = c(0.085, 0.46), # 0.64 puts it in the top panel
        legend.margin = margin(c(1, 1, 1, 1), unit = 'mm'),
        legend.spacing.y = unit(1,'mm'), # spacing between title & items
        legend.key.size = unit(3.0,'mm'), # spacing between items
        legend.title = element_text(face = 'bold', size = 7),
        legend.text = element_text(size = 7))

figure_1 = cowplot::plot_grid(figure_1_upper, figure_1_lower, nrow = 2, axis = 'l',
                              align = 'v', rel_heights = c(1.0, 0.43))

figure_1

ggsave('images/wtar-figure-1.pdf', width = fig_1_width, height = fig_1_height,
       units = 'cm')
```

# Discussion

Relevance to concept of cognitive reserve. This can lead to circular reasoning if the premorbid measure is not reliable. e.g. If a person with PD-MCI has a low measure of premorbid function, then this supports the concept of a strong cognitive reserve being protective against subsequent decline. But if the disease process reduces performance on that measure, then the inference is no longer valid. Evidence of that reliability is required to strengthen inferences in this area.

The WTAR is outdated inasmuch as it was originally devised to estimate WAIS-III scores. Third party predictions for the current WAIS-IV have been published,[@bright2020_ComparisonMethodsEstimating] while WAIS-V is under development

The WTAR (and NART) are also limited in that they are inherently tied to peculiarities of English. Many other languages have no equivalent irregularities in their mappings of graphemes to phonemes. In subsequent revisions of the PD-MCI criteria, if premorbid measures continue to be advocated, more attention should be given to alternative techniques[@franzen1997_MethodsEstimatingPremorbid] that could be valid in a wider international context.


# References

